{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-Models-HIDS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NganTran-0017/HIDS/blob/main/DL_Models_HIDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mzc_frRBqSW"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baLX852RsM7a"
      },
      "source": [
        "#@title Specify parameters before running\n",
        "\n",
        "\n",
        "SZ =  0.3#@param {type:\"number\"}         # Indicate a fraction number to sample train set when it's too big. Located in Data Partition\n",
        "\n",
        "SEQ_WINDOW =  10#@param {type:\"integer\"} # Indicate the window length to parse the sequence into. Used in Data Parsing section\n",
        "\n",
        "BATCH_SZ =  256#@param {type:\"integer\"} # Indicate the window length to parse the sequence into. Used in Data Parsing section\n",
        "\n",
        "EPOCHS =  2#@param {type:\"integer\"} # Indicate the window length to parse the sequence into. Used in Data Parsing section\n",
        "\n",
        "# Indicate to clean data or not. Used in Data Cleaning section\n",
        "CLEAN = False #@param {type:\"boolean\"}\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDDU0UkRplxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fab784d-a3e2-4f75-a7b8-57e2c69886b0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score, roc_curve, auc, recall_score, precision_score,plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "\n",
        "## Tokenizing syscall sequences into n-grams of 6\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import ngrams"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4SwCY4NVnCL"
      },
      "source": [
        "#**Processing data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQhzBhHanZuz"
      },
      "source": [
        "Use the given datasets in our GitHub to load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHtiWDffY_so",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9294da67-259f-47a4-dd21-564b7809081f"
      },
      "source": [
        "  ## Uncomment each line to load Normal data\n",
        "\n",
        "# Synthetic sendmail csv_file = ['bounce-1.int', 'bounce.int', 'bounce-2.int', 'plus.int', 'queue.int', 'sendmail.daemon.int', 'sendmail.log.int']; DATA = 'Synthetic Sendmail'; DATA_I='Synthetic_Sendmail'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/normal-data/bounce-1.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/normal-data/bounce.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/normal-data/bounce-2.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/normal-data/plus.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/normal-data/queue.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/normal-data/sendmail.daemon.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/normal-data/sendmail.log.int'\n",
        "\n",
        "# LIVE LPR csv_file = ['lpr-normal-10.txt', 'lpr-normal-11.txt']; DATA = 'Live Lpr'; DATA_I='Live-Lpr' \n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/4.%20Live%20lpr/Normal/real/lpr-normal-11.txt'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/4.%20Live%20lpr/Normal/real/lpr-normal-10.txt'\n",
        "\n",
        "# MIT live lpr csv_file = [ 'mit-lpr-mar.txt']; DATA = 'MIT Live Lpr'; DATA_I='MIT-Lpr' \n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/MIT/mit-lpr-mar.txt'\n",
        "\n",
        "# LOGIN and PS csv_file = [ 'login-normal.txt', 'ps-normal.txt']; DATA = 'Login and Ps'; DATA_I =\"Login-and-Ps\"\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/7.Login_and_ps/normal/login-normal.txt'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/7.Login_and_ps/normal/ps-normal.txt'\n",
        "\n",
        "# INETD csv_file = [ 'inetd-live-unm.int']; DATA = 'Inetd';DATA_I =\"Inetd\" \n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/8.Inetd/inetd-live-unm.int'\n",
        "\n",
        "# STIDE \n",
        "csv_file = [ 'stide-normal-500k.txt']; DATA = 'Stide';DATA_I ='Stide' \n",
        "!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/10.Stide/stide-normal-500k.txt'\n",
        "\n",
        "# Live Named  ==> Best result csv_file = [ 'normal-named-live-2k.txt']; DATA = 'Live Named';DATA_I ='Live-Named' \n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/6.Live_named/normal-named-live-2k.txt'\n",
        "\n",
        "# Xlock csv_file = [ 'normal-xlock.txt']; DATA = 'Xlock';DATA_I='Xlock' \n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/5.xlock/normal-xlock.txt'\n",
        "\n",
        "# Synthetic Ftp csv_file = [ 'nonself1.int','nonself2.int']; DATA = 'Synthetic Ftp'; DATA_I='Synthetic-Ftp'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/2.Synthetic%20Ftp/nonself1.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/2.Synthetic%20Ftp/nonself2.int'\n",
        "\n",
        "# Synthetic lpr csv_file = ['syn.int']; DATA = 'Synthetic Lpr';DATA_I='Synthetic-Lpr'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/3.Synthetic-lpr/syn.int'\n",
        "\n",
        "# Concat a list of files into normal df\n",
        "list_of_dataframes = []\n",
        "for filename in csv_file:\n",
        "    list_of_dataframes.append(pd.read_csv(filename, sep='\\t', header=None, engine='python'))\n",
        "df = pd.concat(list_of_dataframes)\n",
        "\n",
        "# Check number of columns, if > 2, then drop the excess\n",
        "if len(df.columns) > 2:\n",
        "    df=df.drop(labels=None, axis=1, columns = [2,3])\n",
        "df =df.rename(columns= {0:\"PID\", 1:\"Syscall\"})\n",
        "\n",
        "print('Normal data size:', df.shape)\n",
        "\n",
        "\n",
        "  ## Uncomment each line to load Intrusion data:\n",
        "\n",
        "# Synthetic sendmail csv_file = ['sm-10763.int', 'fwd-loops-1.int', 'fwd-loops-2.int', 'fwd-loops-3.int', 'fwd-loops-4.int', 'fwd-loops-5.int','sm-280.int', 'sm-314.int','sm-10801.int', 'sm-10814.int']\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/Intrusion-trace-data/fwd-loops-1.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/Intrusion-trace-data/fwd-loops-2.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/Intrusion-trace-data/fwd-loops-3.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/Intrusion-trace-data/fwd-loops-4.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/Intrusion-trace-data/fwd-loops-5.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/Intrusion-trace-data/sm-10763.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/Intrusion-trace-data/sm-280.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/Intrusion-trace-data/sm-314.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/Intrusion-trace-data/sm-10801.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/1.Synthetic%20Sendmail/Intrusion-trace-data/sm-10814.int'\n",
        "\n",
        "# LIVE LPR csv_file =['exploit-unm.int'] \n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/4.%20Live%20lpr/Intrusion/exploit-unm.int'\n",
        "\n",
        "# MIT live lpr csv_file = [ 'exploit-ai.int'] \n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/MIT/exploit-ai.int'\n",
        "\n",
        "# LOGIN and PS csv_file = [ 'login-homegrown.int','ps-homegrown.int','login-recovered.int','ps-recovered.int']\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/7.Login_and_ps/intrusion/ps-recovered.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/7.Login_and_ps/intrusion/ps-homegrown.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/7.Login_and_ps/intrusion/login-recovered.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/7.Login_and_ps/intrusion/login-homegrown.int'\n",
        "\n",
        "# INETD csv_file = [ 'inetd-intrusion.int'] \n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/8.Inetd/intrusion/inetd-intrusion.int'\n",
        "\n",
        "# STIDE \n",
        "csv_file = [ 'stide-intrusion'] \n",
        "!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/10.Stide/intrusion/stide-intrusion'\n",
        "\n",
        "# Live Named  ==> Best Result csv_file = [ 'exploit-1.int','exploit-2.int'] \n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/6.Live_named/intrusion/exploit-1.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/6.Live_named/intrusion/exploit-2.int'\n",
        "\n",
        "# Xlock csv_file = [ 'nonself.cs.unm.edu-07.24.97-xlock-2822_new.log.int', 'nonself.cs.unm.edu-07.25.97-xlock-2691_new.log.int']\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/5.xlock/intrusion/nonself.cs.unm.edu-07.25.97-xlock-2691_new.log.int'\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/5.xlock/intrusion/nonself.cs.unm.edu-07.24.97-xlock-2822_new.log.int'\n",
        "\n",
        "# Synthetic Ftp csv_file = [ 'exploit2.int']\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/2.Synthetic%20Ftp/intrusion/exploit2.int'\n",
        "\n",
        "# Synthetic Lpr csv_file = [ 'exploit-unm.int']\n",
        "#!wget 'https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/3.Synthetic-lpr/intrusion/exploit-unm.int'\n",
        "\n",
        "list_of_dataframes = []\n",
        "for filename in csv_file:\n",
        "    list_of_dataframes.append(pd.read_csv(filename, sep=' ', header=None, engine='python'))\n",
        "intrusiondf = pd.concat(list_of_dataframes)\n",
        "\n",
        "if len(intrusiondf.columns) > 2:\n",
        "    intrusiondf = intrusiondf.drop(labels=None, axis=1, columns = [2,3])\n",
        "intrusiondf = intrusiondf.rename(columns= {0:\"PID\", 1:\"Syscall\"})\n",
        "\n",
        "print('intrusion data size: ', intrusiondf.shape)\n",
        "\n",
        "print('Normal:',df.head(3))\n",
        "#print(df['PID'].value_counts())\n",
        "print('Intrusion:',intrusiondf.head())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-09 23:35:40--  https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/10.Stide/stide-normal-500k.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4048353 (3.9M) [text/plain]\n",
            "Saving to: ‘stide-normal-500k.txt’\n",
            "\n",
            "stide-normal-500k.t 100%[===================>]   3.86M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-11-09 23:35:40 (54.7 MB/s) - ‘stide-normal-500k.txt’ saved [4048353/4048353]\n",
            "\n",
            "Normal data size: (499722, 2)\n",
            "--2021-11-09 23:35:43--  https://raw.githubusercontent.com/NganTran-0017/HIDS/main/Datasets/UNM/10.Stide/intrusion/stide-intrusion\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1427163 (1.4M) [text/plain]\n",
            "Saving to: ‘stide-intrusion’\n",
            "\n",
            "stide-intrusion     100%[===================>]   1.36M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-11-09 23:35:43 (26.0 MB/s) - ‘stide-intrusion’ saved [1427163/1427163]\n",
            "\n",
            "intrusion data size:  (205935, 2)\n",
            "Normal:    PID  Syscall\n",
            "0  405       90\n",
            "1  405      125\n",
            "2  405      125\n",
            "Intrusion:    PID  Syscall\n",
            "0  930       90\n",
            "1  930      125\n",
            "2  930      125\n",
            "3  930      106\n",
            "4  930        5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09eozmwq9CFh"
      },
      "source": [
        "**Change to covert all syscall of 1 PID into a data record. Pasrse each data record to a length of 10 or 15, clean frequent records.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "6OgG7OGdQ0Oi",
        "outputId": "9535ab7e-ace5-49ee-bf9c-fdc4d056da8a"
      },
      "source": [
        "print('Number of unique PID in normal data:', len(df['PID'].value_counts()))\n",
        "df"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique PID in normal data: 279\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PID</th>\n",
              "      <th>Syscall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>405</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>405</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>405</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>405</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>405</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499717</th>\n",
              "      <td>20010</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499718</th>\n",
              "      <td>20010</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499719</th>\n",
              "      <td>20010</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499720</th>\n",
              "      <td>20010</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499721</th>\n",
              "      <td>20010</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>499722 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          PID  Syscall\n",
              "0         405       90\n",
              "1         405      125\n",
              "2         405      125\n",
              "3         405      106\n",
              "4         405        5\n",
              "...       ...      ...\n",
              "499717  20010        4\n",
              "499718  20010        4\n",
              "499719  20010        4\n",
              "499720  20010        4\n",
              "499721  20010        4\n",
              "\n",
              "[499722 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "D3SbpSdF7YDQ",
        "outputId": "0437f9da-0efc-474b-9931-02a1355fbbff"
      },
      "source": [
        "print('Number of unique PID in intrusion data:', len(intrusiondf['PID'].value_counts()))\n",
        "intrusiondf"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique PID in intrusion data: 105\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PID</th>\n",
              "      <th>Syscall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>930</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>930</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>930</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>930</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>930</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205930</th>\n",
              "      <td>1202</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205931</th>\n",
              "      <td>1202</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205932</th>\n",
              "      <td>1202</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205933</th>\n",
              "      <td>1202</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205934</th>\n",
              "      <td>1202</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205935 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         PID  Syscall\n",
              "0        930       90\n",
              "1        930      125\n",
              "2        930      125\n",
              "3        930      106\n",
              "4        930        5\n",
              "...      ...      ...\n",
              "205930  1202       45\n",
              "205931  1202       45\n",
              "205932  1202       45\n",
              "205933  1202       45\n",
              "205934  1202       45\n",
              "\n",
              "[205935 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvHyIKtq9BCG"
      },
      "source": [
        "**Create syscall sequence per pid**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXOlXVgyOHmA",
        "outputId": "bd3d6ba4-41ce-4e50-94a0-51e307c1f3d1"
      },
      "source": [
        "# This function groups data by PID, so the sequences appear by PID instead of by order, in case it was interrupted by other PID\n",
        "## It returns a dict with PID as key and syscall seq as item\n",
        "def group_syscalls_by_pid (data):\n",
        "  seq_per_pid = {}\n",
        "  for p in data['PID'].unique():\n",
        "    filt = data['PID'] == p\n",
        "    seq = data.loc[filt]['Syscall'].values.astype(str)\n",
        "    seq_per_pid[p] = ' '.join(seq)\n",
        "  return seq_per_pid\n",
        "\n",
        "# Group normal df by PID and drop PID column\n",
        "normal_seq_per_pid = group_syscalls_by_pid(df)\n",
        "print('Number of unique PID in normal:', len(normal_seq_per_pid))\n",
        "#print('Normal PIDs and its sequences: ',normal_seq_per_pid)\n",
        "\n",
        "# Do the same thing to intrusion PID\n",
        "intrusion_seq_per_pid = group_syscalls_by_pid(intrusiondf)\n",
        "print('Number of unique PID in intrusion:', len(intrusion_seq_per_pid))\n",
        "#print('Intrusion PIDs and its sequences: ', intrusion_seq_per_pid)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique PID in normal: 279\n",
            "Number of unique PID in intrusion: 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3M7Z4L6modm",
        "outputId": "ce1972f9-42a0-4e2f-c2e8-91d1b1fe031c"
      },
      "source": [
        "# Drop a sequence if its total len is less than 3\n",
        "def remove_small_seq(pid_seq_dict):\n",
        "  removed_pid = []\n",
        "  for pid in pid_seq_dict:\n",
        "    seq_list = pid_seq_dict[pid].split()\n",
        "    if len(seq_list) < 3:\n",
        "      print('Remove PID %d which only has %d syscals in its sequence: %s' % (pid, len(seq_list), pid_seq_dict[pid]))\n",
        "      removed_pid.append(pid)\n",
        "\n",
        "  [pid_seq_dict.pop(pid) for pid in removed_pid]\n",
        "  return pid_seq_dict\n",
        "\n",
        "# Clean small intrusion sequences\n",
        "print('Clean small normal seq: \\nNum PID in Normal before:', len(normal_seq_per_pid))\n",
        "normal_seq_per_pid = remove_small_seq(normal_seq_per_pid)\n",
        "print('Num PID in Normal after:', len(normal_seq_per_pid))\n",
        "\n",
        "# Clean small intrusion sequences\n",
        "print('\\n\\nClean small intrusion seq: \\nNum PID in Intrusion before:', len(intrusion_seq_per_pid))\n",
        "intrusion_seq_per_pid = remove_small_seq(intrusion_seq_per_pid)\n",
        "print('Num PID in Intrusion after:', len(intrusion_seq_per_pid))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean small normal seq: \n",
            "Num PID in Normal before: 279\n",
            "Num PID in Normal after: 279\n",
            "\n",
            "\n",
            "Clean small intrusion seq: \n",
            "Num PID in Intrusion before: 105\n",
            "Num PID in Intrusion after: 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKXCVvBRF9fB"
      },
      "source": [
        "## **Data Parsing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ph244VM5_86n",
        "outputId": "afc45db5-82b7-46b2-dcb4-76eae590ee2a"
      },
      "source": [
        "## Parse an entire Syscall seq per PID into smaller sequences of size 15\n",
        "def parse_seq(seq_per_pid):\n",
        "  sequences = pd.DataFrame()\n",
        "  for p in seq_per_pid:\n",
        "    token = word_tokenize(seq_per_pid[p])  # Tokenize the string of sequence\n",
        "\n",
        "    # Parse the sequence into length of 15\n",
        "    sequences=sequences.append(list(nltk.ngrams(token, SEQ_WINDOW, pad_right=True, right_pad_symbol=-1)))\n",
        "    #print('PID %d - seq len: %d'% (p, len(sequences)))\n",
        "  return sequences\n",
        "\n",
        "normal = parse_seq(normal_seq_per_pid)\n",
        "\n",
        "normal"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90</td>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1158</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>499722 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    1    2    3   4   5   6   7   8    9\n",
              "0      90  125  125  106   5  90   6   5   3   90\n",
              "1     125  125  106    5  90   6   5   3  90   90\n",
              "2     125  106    5   90   6   5   3  90  90   90\n",
              "3     106    5   90    6   5   3  90  90  90    6\n",
              "4       5   90    6    5   3  90  90  90   6  125\n",
              "...   ...  ...  ...  ...  ..  ..  ..  ..  ..  ...\n",
              "1156    4    4    4    4   4  -1  -1  -1  -1   -1\n",
              "1157    4    4    4    4  -1  -1  -1  -1  -1   -1\n",
              "1158    4    4    4   -1  -1  -1  -1  -1  -1   -1\n",
              "1159    4    4   -1   -1  -1  -1  -1  -1  -1   -1\n",
              "1160    4   -1   -1   -1  -1  -1  -1  -1  -1   -1\n",
              "\n",
              "[499722 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "oyAnefsOQiIU",
        "outputId": "eacc75df-0087-4d2c-d222-6b095d1a9739"
      },
      "source": [
        "print('Parsing Intrusion')\n",
        "intrusion = parse_seq(intrusion_seq_per_pid)\n",
        "intrusion"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing Intrusion\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90</td>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205935 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2    3   4   5   6   7   8    9\n",
              "0    90  125  125  106   5  90   6   5   3   90\n",
              "1   125  125  106    5  90   6   5   3  90   90\n",
              "2   125  106    5   90   6   5   3  90  90   90\n",
              "3   106    5   90    6   5   3  90  90  90    6\n",
              "4     5   90    6    5   3  90  90  90   6  125\n",
              "..  ...  ...  ...  ...  ..  ..  ..  ..  ..  ...\n",
              "21   45   45   45   45  45  -1  -1  -1  -1   -1\n",
              "22   45   45   45   45  -1  -1  -1  -1  -1   -1\n",
              "23   45   45   45   -1  -1  -1  -1  -1  -1   -1\n",
              "24   45   45   -1   -1  -1  -1  -1  -1  -1   -1\n",
              "25   45   -1   -1   -1  -1  -1  -1  -1  -1   -1\n",
              "\n",
              "[205935 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WjkWBLbqW3u"
      },
      "source": [
        "Start tokenizing system calls into 6-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "376udEA5GdPB"
      },
      "source": [
        " ## **Data Cleaning**\n",
        " Remove rows that exist in both normal and intrusion df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdvbPMAOl-Cn"
      },
      "source": [
        "## Get % of duplicates in both datasets\n",
        "\n",
        "def clean_data (normal, intrusion):\n",
        "  # Convert normal df to set, and intrusion df to set\n",
        "  normal_list = normal.values.tolist()\n",
        "  intrusion_list = intrusion.values.tolist()\n",
        "  normal_set = set(tuple(i) for i in normal_list)\n",
        "  intrusion_set = set(tuple(i) for i in intrusion_list)\n",
        "  print('List sz vs. Set sz of normal sequences: %d vs. %d'% (len(normal_list),len(normal_set)) )\n",
        "  print('List sz vs. Set sz of intrusion sequences: %d vs. %d'% (len(intrusion_list),len(intrusion_set)) )\n",
        "\n",
        "  # Only remove intrusion sequences that exist in normal set because these sequences are just general actions which should not be labelled intrusion\n",
        "  c_intrusion = intrusion_set - normal_set\n",
        "  #c_normal = normal_set - intrusion_set\n",
        "  if len(c_intrusion) == 0 and len(c_normal) == 0:\n",
        "    print(DATA+' No Duplication!')\n",
        "  if len(c_intrusion) > 0:\n",
        "    #intrusion = pd.DataFrame(c_intrusion)\n",
        "    intrusion = pd.DataFrame(intrusion_set)\n",
        "  else:\n",
        "    intrusion = pd.DataFrame(intrusion_set)\n",
        "\n",
        "  #if len(c_normal) > 0:\n",
        "  #  normal = pd.DataFrame(c_normal)\n",
        "  #else:\n",
        "  normal = pd.DataFrame(normal_set)\n",
        "\n",
        "  print('After cleaning: \\nNormal sz:', len(normal), ' CLEAN Intrusion sz:', len(c_intrusion) )\n",
        "  return normal, intrusion\n",
        "\n",
        "if CLEAN:\n",
        "  normal, intrusion = clean_data(normal, intrusion)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "MuylikQOw7da",
        "outputId": "7f11763c-a73f-4f73-b1e3-f96086c66a7b"
      },
      "source": [
        "normal"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90</td>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1158</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>499722 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    1    2    3   4   5   6   7   8    9\n",
              "0      90  125  125  106   5  90   6   5   3   90\n",
              "1     125  125  106    5  90   6   5   3  90   90\n",
              "2     125  106    5   90   6   5   3  90  90   90\n",
              "3     106    5   90    6   5   3  90  90  90    6\n",
              "4       5   90    6    5   3  90  90  90   6  125\n",
              "...   ...  ...  ...  ...  ..  ..  ..  ..  ..  ...\n",
              "1156    4    4    4    4   4  -1  -1  -1  -1   -1\n",
              "1157    4    4    4    4  -1  -1  -1  -1  -1   -1\n",
              "1158    4    4    4   -1  -1  -1  -1  -1  -1   -1\n",
              "1159    4    4   -1   -1  -1  -1  -1  -1  -1   -1\n",
              "1160    4   -1   -1   -1  -1  -1  -1  -1  -1   -1\n",
              "\n",
              "[499722 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b5U4P_HrSEm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "4322d211-e29e-4de2-9a3b-8c1029ebc760"
      },
      "source": [
        "intrusion"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90</td>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>125</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>6</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205935 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2    3   4   5   6   7   8    9\n",
              "0    90  125  125  106   5  90   6   5   3   90\n",
              "1   125  125  106    5  90   6   5   3  90   90\n",
              "2   125  106    5   90   6   5   3  90  90   90\n",
              "3   106    5   90    6   5   3  90  90  90    6\n",
              "4     5   90    6    5   3  90  90  90   6  125\n",
              "..  ...  ...  ...  ...  ..  ..  ..  ..  ..  ...\n",
              "21   45   45   45   45  45  -1  -1  -1  -1   -1\n",
              "22   45   45   45   45  -1  -1  -1  -1  -1   -1\n",
              "23   45   45   45   -1  -1  -1  -1  -1  -1   -1\n",
              "24   45   45   -1   -1  -1  -1  -1  -1  -1   -1\n",
              "25   45   -1   -1   -1  -1  -1  -1  -1  -1   -1\n",
              "\n",
              "[205935 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GMYBPNarqFf"
      },
      "source": [
        "## **Histogram of Processed Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB8QSEMJ4h0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "2126d1cc-0165-4015-8e84-d1e582154480"
      },
      "source": [
        "# After Cleaning\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.hist(normal[0], label='Normal', alpha=0.6, density=True)\n",
        "plt.hist(intrusion[0], label='Intrusion', color='tomato', alpha=0.6, density=True)\n",
        "plt.legend()\n",
        "plt.ylabel('Proportions')\n",
        "plt.xlabel('Syscall num')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "#plt.xticks(np.arange(0,200,10))\n",
        "plt.title('An Overlaid Histogram of Syscall Proportions in Normal and Intrusion Data from ' + DATA,y=1.02, fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk_fLEaHr0SL"
      },
      "source": [
        "**Labeling Sequences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KILRKFiA2EV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aaf79b3-6a38-4754-98d7-39bc709765a5"
      },
      "source": [
        "# Intrusion sequences is labeled 1. Rename columns of the dataframe\n",
        "intrusion['Label'] = 1\n",
        "print(intrusion.head(5), '\\n')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0    1    2    3   4   5   6   7   8    9  Label\n",
            "0   90  125  125  106   5  90   6   5   3   90      1\n",
            "1  125  125  106    5  90   6   5   3  90   90      1\n",
            "2  125  106    5   90   6   5   3  90  90   90      1\n",
            "3  106    5   90    6   5   3  90  90  90    6      1\n",
            "4    5   90    6    5   3  90  90  90   6  125      1 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN2KngnOyG5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40851063-224c-4e51-a46b-799d584dac90"
      },
      "source": [
        "# Normal sequences is labeled 0. Rename columns of the dataframe\n",
        "normal['Label'] = 0\n",
        "print(normal.head(5), '\\n')\n",
        "\n",
        "print('Normal len:',len(normal),'\\nIntrusion len:', len(intrusion))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0    1    2    3   4   5   6   7   8    9  Label\n",
            "0   90  125  125  106   5  90   6   5   3   90      0\n",
            "1  125  125  106    5  90   6   5   3  90   90      0\n",
            "2  125  106    5   90   6   5   3  90  90   90      0\n",
            "3  106    5   90    6   5   3  90  90  90    6      0\n",
            "4    5   90    6    5   3  90  90  90   6  125      0 \n",
            "\n",
            "Normal len: 499722 \n",
            "Intrusion len: 205935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ohcyx-nmoYj"
      },
      "source": [
        "## **Partition Training and Testing dataset 70/30**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ7j7n01sZE1"
      },
      "source": [
        "If there is not enough data from either class, bootstrap to generate more data and create a balanced sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcj-XXjMZ57h",
        "outputId": "4973de43-3ead-4a50-be50-c922b7b0d84a"
      },
      "source": [
        "# combine normal and intrusion data and split them into training and testing sets\n",
        "df = normal.append(intrusion, ignore_index=True).astype(int)\n",
        "print('Df sz:', df.shape)\n",
        "\n",
        "# Spliting into training and testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df['Label'], test_size = 0.30, shuffle=True)\n",
        "\n",
        "# Reset index of training and testing sets\n",
        "x_train.reset_index(drop=True, inplace=True); y_train.reset_index(drop=True, inplace=True)\n",
        "x_test.reset_index(drop=True, inplace=True);  y_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print('Train sz:',len(x_train), len(y_train))\n",
        "intrusion_train = y_train.loc[y_train == 1]\n",
        "normal_train = y_train.loc[y_train == 0]\n",
        "print('Train set: Intrusion vs. Normal cases', len(y_train.iloc[intrusion_train] ), len(y_train.iloc[normal_train] ))\n",
        "\n",
        "print('Test sz:', len(x_test), len(y_test))\n",
        "intrusion_test = y_test.loc[y_test == 1]\n",
        "normal_test = y_test.loc[y_test == 0]\n",
        "print('Test set: Intrusion vs. Normal cases', len(y_test.iloc[intrusion_test] ), len(y_test.iloc[normal_test] ))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Df sz: (705657, 11)\n",
            "Train sz: 493959 493959\n",
            "Train set: Intrusion vs. Normal cases 144103 349856\n",
            "Test sz: 211698 211698\n",
            "Test set: Intrusion vs. Normal cases 61832 149866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "c7NZyzbVcNTk",
        "outputId": "14e57c8f-c350-4d03-d671-0f0a87cf2162"
      },
      "source": [
        "# Bootstrap training data\n",
        "\n",
        "## Lived-name has more intrusion cases than normal cases (189 > 71) --> bootstrap normal cases only\n",
        "x_train['Label'] = y_train\n",
        "\n",
        "if len(intrusion_train) > len(normal_train):\n",
        "  x_train = x_train.iloc[intrusion_train.index].append(x_train.iloc[normal_train.index].sample(n = len(intrusion_train), replace=True), ignore_index=True) #upsampled normal data and add to train set\n",
        "else:\n",
        "  x_train = x_train.iloc[normal_train.index].append(x_train.iloc[intrusion_train.index].sample(n = len(normal_train), replace=True), ignore_index=True) #upsampled intrusion data and add to train set\n",
        "\n",
        "#x_train = x_train.append(x_train.sample(frac=1), ignore_index=True) # Bootstrap training data in case there is not enough data\n",
        "x_train = x_train.sample(frac= SZ) # Shuffle data with a SZ proportion\n",
        "x_train.reset_index(drop=True, inplace=True)\n",
        "y_train = x_train['Label']\n",
        "x_train.drop(columns='Label', inplace=True)\n",
        "x_train"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209909</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209910</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209911</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209912</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209913</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>209914 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0  1  2  3  4  5  6  7  8  9\n",
              "0       4  4  4  4  4  4  4  4  4  4\n",
              "1       4  4  4  4  4  4  4  4  4  4\n",
              "2       4  4  4  4  4  4  4  4  4  4\n",
              "3       4  4  4  4  4  4  4  4  4  4\n",
              "4       4  4  4  4  4  4  4  4  4  4\n",
              "...    .. .. .. .. .. .. .. .. .. ..\n",
              "209909  4  4  4  4  4  4  4  4  4  4\n",
              "209910  4  4  4  4  4  4  4  4  4  4\n",
              "209911  4  4  4  4  4  4  4  4  4  4\n",
              "209912  4  4  4  4  4  4  4  4  4  6\n",
              "209913  4  4  4  4  4  4  4  4  4  4\n",
              "\n",
              "[209914 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnDDh0TWsyS7",
        "outputId": "a7b60bfa-ebb3-47ac-92ee-67bc0e4fc071"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         1\n",
              "2         1\n",
              "3         1\n",
              "4         0\n",
              "         ..\n",
              "209909    1\n",
              "209910    0\n",
              "209911    1\n",
              "209912    0\n",
              "209913    1\n",
              "Name: Label, Length: 209914, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "JFNhH053qfct",
        "outputId": "0cc5cd20-72ec-4840-b416-5608634767ed"
      },
      "source": [
        "x_test"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211693</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211694</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211695</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211696</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211697</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>211698 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0  1  2  3   4  5  6  7  8  9\n",
              "0       4  4  4  4   4  4  4  4  4  4\n",
              "1       4  4  4  4   4  4  4  4  4  4\n",
              "2       4  4  4  4   4  4  4  4  4  4\n",
              "3       4  4  4  4   4  4  4  4  4  4\n",
              "4       4  4  4  4   4  4  4  4  4  4\n",
              "...    .. .. .. ..  .. .. .. .. .. ..\n",
              "211693  4  4  4  4  45  4  4  4  4  4\n",
              "211694  4  4  4  4   4  4  4  4  4  4\n",
              "211695  4  4  4  4   4  4  4  4  4  4\n",
              "211696  4  4  4  4   4  4  4  4  4  4\n",
              "211697  4  4  4  4   4  4  4  4  4  4\n",
              "\n",
              "[211698 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0UCA-ZuXHX_"
      },
      "source": [
        "\n",
        "# **Performance Measures**\n",
        "\n",
        "\n",
        "1.   Function calc_false_positive: Calculates FPR\n",
        "2.   Function print_performance: Formats printing performance metrics and ROC curve for each model\n",
        "3.   Function color_confusion_matrix: prints out a heatmap of confusion matrix in blue color scale\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA1PZX4XBNLO"
      },
      "source": [
        "# This function calculate False Positive Rate given a confusion matrix\n",
        "def calc_false_positive (cmatrix):\n",
        "  specificity = cmatrix[0,0]/(cmatrix[0,0] + cmatrix[0,1])\n",
        "  return 1-specificity\n",
        "\n",
        "# This function prints performance metrics and ROC curve given the model name, true labels and predicted labels\n",
        "def print_performance( model_name, true_labels, pred_labels):\n",
        "  # rows are actual, columns are predicted\n",
        "  cmatrix = confusion_matrix(true_labels, pred_labels)\n",
        "  fpr = calc_false_positive(cmatrix)\n",
        "\n",
        "  print('Confusion Matrix: \\n',cmatrix)\n",
        "  print('\\nTesting Accuracy: %.2f'% metrics.accuracy_score(true_labels, pred_labels))\n",
        "  print('Precision:%.2f'%  metrics.precision_score(true_labels, pred_labels))\n",
        "  print('Recall: %.2f'% metrics.recall_score(true_labels, pred_labels))\n",
        "  print('False Positive Rate: %.2f'% fpr)\n",
        "  print('\\nClassification report:', classification_report(true_labels, pred_labels), sep='\\n')\n",
        "  print('AUC: %.2f'% roc_auc_score(true_labels, pred_labels))\n",
        "\n",
        "  false_positive_rate, recall, thresholds = roc_curve(true_labels, pred_labels)\n",
        "  roc_auc = auc(false_positive_rate, recall)\n",
        "  plt.figure()\n",
        "  if CLEAN: clean_status='Clean '\n",
        "  else: clean_status ='Overlapped and Duplicated '\n",
        "  plt.title( model_name+' ROC Curve on '+ clean_status + DATA + ' with Seq Len of '+ str(SEQ_WINDOW))\n",
        "  plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.2f' %roc_auc)\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.plot([0,1], [0,1], 'r--')\n",
        "  plt.xlim([0.0,1.0])\n",
        "  plt.ylim([0.0,1.1])\n",
        "  plt.ylabel('Recall')\n",
        "  plt.xlabel('False Positive Rate (1-Specificity)')\n",
        "  #plt.savefig(model_name+'-ROC.jpg')\n",
        "  plt.show()\n",
        "\n",
        "# Plot a heatmap of confusion matrix given the model name, a classifier model, testing data and the predicted label\n",
        "def color_confusion_matrix( model_name, model, x_test, y_test, y_predicted):\n",
        "  class_names = ['Normal', 'Intrusion']\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(6, 6))\n",
        "  plot_confusion_matrix(model, x_test, y_test, display_labels=class_names, \n",
        "                        values_format='d', ax = ax, cmap=plt.cm.Blues)\n",
        "  plt.title('Confusion Matrix of ' + str(model_name))\n",
        "  #plt.savefig(model_name+'-CM.jpg')\n",
        "  plt.show()\n",
        "\n",
        "  cmatrix = confusion_matrix(y_test, y_predicted)\n",
        "  print(cmatrix)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1SbGMBTCCcw"
      },
      "source": [
        "# Graphing overlaid ROC curves, where each one represents a model AUC score\n",
        "def graph_multi_ROC ():\n",
        "  # Set color for each model\n",
        "  colors = {'KM': 'lightcoral','LR': 'darkorange', 'SVM':'lime', 'NB': 'steelblue',\n",
        "            'NN': 'purple','DT': 'magenta','RF': 'deeppink','KNN': 'darkturquoise',\n",
        "            'BERT': 'darkred', 'GPT': 'blue'}\n",
        "  # Set marker for each model          \n",
        "  markers = {'KM':'1--','LR': 'v--', 'SVM': '^--', 'NN': '*--', 'DT': 'o--', 'RF': '+--', 'KNN': '.--', 'NB': 'x--', 'BERT':'<--', 'GPT': '>--'}\n",
        "  \n",
        "  plt.figure(figsize=(9,6))\n",
        "  try:\n",
        "    plt.plot(KM_test.get('fpr'), KM_test.get('tpr'), markers.get('KM'), color=colors.get('KM'),  label=\"KM - AUC=\" + str(KM_test.get('auc').round(3)))\n",
        "    plt.plot(LR_test.get('fpr'), LR_test.get('tpr'), markers.get('LR'), color=colors.get('LR'),  label=\"LR - AUC=\" + str(LR_test.get('auc').round(3)))\n",
        "    plt.plot(SVM_test.get('fpr'),SVM_test.get('tpr'),markers.get('SVM'),color=colors.get('SVM'), label=\"SVM - AUC=\"+ str(SVM_test.get('auc').round(3)))\n",
        "    plt.plot(NN_test.get('fpr'), NN_test.get('tpr'), markers.get('NN'), color=colors.get('NN'),  label=\"NN - AUC=\" + str(NN_test.get('auc').round(3)))\n",
        "    plt.plot(DT_test.get('fpr'), DT_test.get('tpr'), markers.get('DT'), color=colors.get('DT'),  label=\"DT - AUC=\" + str(DT_test.get('auc').round(3)))\n",
        "    plt.plot(RF_test.get('fpr'), RF_test.get('tpr'), markers.get('RF'), color=colors.get('RF'),  label=\"RF - AUC=\" + str(RF_test.get('auc').round(3)))\n",
        "    plt.plot(KNN_test.get('fpr'),KNN_test.get('tpr'),markers.get('KNN'),color=colors.get('KNN'), label=\"KNN - AUC=\"+ str(KNN_test.get('auc').round(3)))\n",
        "    plt.plot(NB_test.get('fpr'), NB_test.get('tpr'), markers.get('NB'), color=colors.get('NB'),  label=\"NB - AUC=\" + str(NB_test.get('auc').round(3)))\n",
        "  except:\n",
        "    print('only performances of BERT and GPT are available')\n",
        "\n",
        "  plt.plot(BERT_test.get('fpr'),BERT_test.get('tpr'), markers.get('BERT'), color=colors.get('BERT'),  label=\"BERT - AUC=\"+ str(BERT_test.get('auc').round(3)))\n",
        "  plt.plot(GPT_test.get('fpr'),GPT_test.get('tpr'), markers.get('GPT'), color=colors.get('GPT'),  label=\"GPT-2 - AUC=\"+ str(GPT_test.get('auc').round(3)))\n",
        "\n",
        "  plt.plot([0,1], [0,1], 'k--', label='Random Chances')\n",
        "  plt.xlim([0.0,1.0])\n",
        "  plt.ylim([0.0,1.02])\n",
        "  plt.ylabel('Recall')\n",
        "  plt.xlabel('False Positive Rate (1-Specificity)')\n",
        "  plt.legend(loc='lower right') \n",
        "  plt.title( 'Testing ROCs on ' + DATA)\n",
        "  #plt.savefig(DATA_I+'-'+train_or_test+'.jpg', dpi = 80)\n",
        "  plt.show()"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ-JMcBqmnN9"
      },
      "source": [
        "# **BERT**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k6L-u3Lmmpb",
        "outputId": "61b0edac-31e9-482c-8328-8061634e5c77"
      },
      "source": [
        "!pip install pytorch_pretrained_bert pytorch-nlp"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.9.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.20.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.10.0.2)\n",
            "Requirement already satisfied: botocore<1.24.0,>=1.23.2 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.23.2)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.2->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.2->boto3->pytorch_pretrained_bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.2->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsHMmMB76B9W"
      },
      "source": [
        "from pytorch_pretrained_bert import BertModel\n",
        "from torch import nn\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_NgiJJQm6Xx"
      },
      "source": [
        "**Prepare for Train and test data for BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDMTse2Jm0Bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124d63b0-0eab-43f3-ed54-1ad4f813991e"
      },
      "source": [
        "train_texts = []\n",
        "for i in range(x_train.shape[0]):\n",
        "     train_texts.append(\" \".join(np.array(x_train.iloc[i,:]).astype(str)))\n",
        "train_texts = tuple(train_texts) \n",
        "\n",
        "test_texts = []\n",
        "for i in range(x_test.shape[0]):\n",
        "     test_texts.append(\" \".join(np.array(x_test.iloc[i,:]).astype(str)))\n",
        "test_texts = tuple(test_texts) \n",
        "\n",
        "train_labels = tuple(y_train.tolist())\n",
        "test_labels = tuple(y_test.tolist())\n",
        "\n",
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(209914, 209914, 211698, 211698)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf2Lbwylm_ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c3fbfc-8168-45a7-87d9-6e7e8bddf72c"
      },
      "source": [
        "# Tokenizer \n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Example\n",
        "tokenizer.tokenize(train_texts[8])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4', '4', '4', '4', '4', '4', '4', '4', '4', '4']"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dp_XAarnZqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd971743-cc98-4218-9fcb-cd1f379a50a5"
      },
      "source": [
        "# Convert to tokens using tokenizer\n",
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:20] + ['[SEP]'], train_texts))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:20] + ['[SEP]'], test_texts))\n",
        "\n",
        "print('Number of Training Sequences:',len(train_tokens), '\\nNumber of Testing Sequences:', len(test_tokens) )       "
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training Sequences: 209914 \n",
            "Number of Testing Sequences: 211698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MH_bWrznbYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89336f2a-bbf2-4605-ded1-f8e815f18e36"
      },
      "source": [
        "# Following is to convert List of words to list of numbers. (Words are replaced by their index in dictionar)\n",
        "train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=20, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=20, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "\n",
        "train_tokens_ids.shape, test_tokens_ids.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((209914, 20), (211698, 20))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B9WKzfendjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f9b38f-92b7-44d8-8817-7fafe8c4535b"
      },
      "source": [
        "# Prepare labels\n",
        "# True if intrusion or False if normal\n",
        "train_y = np.array(train_labels) == 1\n",
        "test_y = np.array(test_labels) == 1\n",
        "train_y.shape, test_y.shape, np.mean(train_y), np.mean(test_y)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((209914,), (211698,), 0.498937660184647, 0.29207644852573006)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1q-b-LKnfbH"
      },
      "source": [
        "# To mask the paddings\n",
        "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZ3gKOtng_v"
      },
      "source": [
        "# Define BERT model\n",
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens, masks=None):\n",
        "        # First Layer\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        \n",
        "        # output layer\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        \n",
        "        return proba\n",
        "      \n",
        "    def train_m(self,x,y,train_mask,epochs,batchsize):\n",
        "      train_tokens_tensor = torch.tensor(x)\n",
        "      train_y_tensor = torch.tensor(y.reshape(-1, 1)).float()\n",
        "      train_masks_tensor = torch.tensor(train_mask)\n",
        "\n",
        "      train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "      train_sampler = RandomSampler(train_dataset)\n",
        "      train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batchsize) \n",
        "\n",
        "\n",
        "      param_optimizer = list(self.sigmoid.named_parameters()) \n",
        "      optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "      optimizer = Adam(self.bert.parameters(), lr=2e-5)\n",
        "      for epoch_num in range(epochs):\n",
        "          self.train() # Training Flag\n",
        "          train_loss = 0\n",
        "          for step_num, batch_data in enumerate(train_dataloader):\n",
        "              \n",
        "              # Load batch on device memory\n",
        "              token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "              # Get the output of the model for provided input\n",
        "              logits = self(token_ids, masks)\n",
        "              \n",
        "              # Loss function\n",
        "              loss_func = nn.BCELoss()\n",
        "\n",
        "              # Calculate Loss\n",
        "              batch_loss = loss_func(logits, labels)\n",
        "              train_loss += batch_loss.item()\n",
        "              \n",
        "              # backpropagate the error\n",
        "              self.zero_grad()\n",
        "              batch_loss.backward()\n",
        "              \n",
        "              # Update the Weights of the Model\n",
        "              clip_grad_norm_(parameters=self.parameters(), max_norm=1.0)\n",
        "              optimizer.step()\n",
        "              \n",
        "              clear_output(wait=True)\n",
        "              print('Epoch: ', epoch_num + 1)\n",
        "              print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_labels) / batchsize, train_loss / (step_num + 1)))        "
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA0ADfkpnjgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7bc143-3bc1-4314-fb0c-1776221d8888"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CZERb2Onk_v"
      },
      "source": [
        "bert_clf = BertBinaryClassifier()\n",
        "bert_clf = bert_clf.cuda()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjM08A0OoGro"
      },
      "source": [
        "**Fine Tune BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUS_cifIn1_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a040f67-cc2f-496e-95b4-6b45454e9c47"
      },
      "source": [
        "# Train BERT NLP\n",
        "bert_clf.train_m(train_tokens_ids,train_y,train_masks, EPOCHS, BATCH_SZ)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n",
            "\r140/819.9765625 loss: 0.6840374820621301 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUTlJLsooNrq"
      },
      "source": [
        "**Evaluate on Testing Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly5Mhn9SoKxw"
      },
      "source": [
        "# Convert token ids to tensor \n",
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "\n",
        "# Convert labels to tensors\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
        "\n",
        "# Convert to tensro for maks\n",
        "test_masks_tensor = torch.tensor(test_masks)\n",
        "\n",
        "\n",
        "# Load Token, token mask and label into Dataloader\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "\n",
        "# Define sampler\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "\n",
        "# Defile test data loader\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1gC8UusoWfo"
      },
      "source": [
        "bert_clf.eval() # Define eval\n",
        "bert_predicted = [] # To Store predicted result\n",
        "all_logits = [] # Actual output that is between 0 to 1 is stored here\n",
        "\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        # Load the batch on gpu memory\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        # Calculate ouput of bert\n",
        "        logits = bert_clf(token_ids, masks)\n",
        "\n",
        "        # Get the numpy logits\n",
        "        numpy_logits = logits.cpu().detach().numpy()  # Detach from the GPU memory\n",
        "        \n",
        "        # Using the threshold find binary \n",
        "        bert_predicted += list(numpy_logits[:, 0] > 0.5)  # Threshold conversion\n",
        "        all_logits += list(numpy_logits[:, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKmOvtXDoiL9"
      },
      "source": [
        "print_performance('BERT',test_y, bert_predicted)\n",
        "\n",
        "# Recording TPR and FPR for the TESTING-ROC curves\n",
        "BERT_test = {}\n",
        "BERT_test['fpr'], BERT_test['tpr'], thresh = roc_curve(test_y, bert_predicted)\n",
        "BERT_test['auc'] = roc_auc_score(test_y, bert_predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxHLceizE90D"
      },
      "source": [
        "#BERT_test = {'fpr': 0.8, 'auc': 0.9}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi1V9tJPDPxh"
      },
      "source": [
        "# Save BERT performance measures to a file\n",
        "def write_to_file (filename, varname, model_name):\n",
        "  file = open(filename, \"a\")\n",
        "  str_dictionary = repr(varname)\n",
        "  file.write(\"{}_test = \".format(model_name) + str_dictionary + \"\\n\")\n",
        "  file.close()\n",
        "\n",
        "write_to_file(\"stide-pm.txt\", BERT_test, 'BERT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSuD_5c43X10"
      },
      "source": [
        "# **GPT-2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HueSQ1KsukV"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-gD9nyo4S1D"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('microsoft/DialoGPT-small')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkYOrTFA4YUN"
      },
      "source": [
        "# Padding sequences from the right to a max length of 20\n",
        "tokenizer.padding_side = \"right\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "train_tokens = tokenizer(train_texts,return_tensors='pt',truncation=True,padding=True,max_length=20)\n",
        "test_tokens = tokenizer(test_texts,return_tensors='pt',truncation=True,padding=True,max_length=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHRofoti4g24"
      },
      "source": [
        "# Following is to convert List of words to list of numbers. (Words are replaced by their index in dictionar)\n",
        "\n",
        "train_tokens_ids = train_tokens.input_ids\n",
        "test_tokens_ids = test_tokens.input_ids\n",
        "\n",
        "train_tokens_ids.shape, test_tokens_ids.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udvDwEdz4haO"
      },
      "source": [
        "train_masks = train_tokens.attention_mask\n",
        "test_masks = test_tokens.attention_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23qklJA_6Q2L"
      },
      "source": [
        "**Create GPT-2 Classifer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LiNms1g6PqS"
      },
      "source": [
        "class GTP2BinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(GTP2BinaryClassifier, self).__init__()\n",
        "        self.gtp2 = GPT2ForSequenceClassification.from_pretrained('microsoft/DialoGPT-small')\n",
        "      \n",
        "    def train_m(self,x,y,train_mask,epochs,batchsize):\n",
        "      train_tokens_tensor = torch.tensor(x)\n",
        "      train_y_tensor = torch.tensor(y.reshape(-1, 1)).long()\n",
        "      train_masks_tensor = torch.tensor(train_mask)\n",
        "\n",
        "      train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "      train_sampler = RandomSampler(train_dataset)\n",
        "      train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batchsize) \n",
        "\n",
        "\n",
        "      # param_optimizer = list(self.gtp2.parameters()) \n",
        "      # optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "      optimizer = Adam(self.gtp2.parameters(), lr=5e-5)\n",
        "      for epoch_num in range(epochs):\n",
        "          self.gtp2.train() # Training Flag\n",
        "          train_loss = 0\n",
        "          for step_num, batch_data in enumerate(train_dataloader):\n",
        "              \n",
        "              # Load batch on device memory\n",
        "              token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "              self.zero_grad()\n",
        "\n",
        "              # Get the output of the model for provided input\n",
        "              outputs = self.gtp2(token_ids,attention_mask=masks,labels=labels)\n",
        "              loss, logits = outputs[:2]\n",
        "              # logits = self(token_ids, masks)\n",
        "              \n",
        "              # Total Loss\n",
        "              train_loss += loss.item()\n",
        "              \n",
        "              # Backward pass the loss\n",
        "              loss.backward()\n",
        "              torch.nn.utils.clip_grad_norm_(self.gtp2.parameters(), 1.0)\n",
        "              \n",
        "              optimizer.step()\n",
        "              logits = logits.detach().cpu().numpy()\n",
        "\n",
        "              clear_output(wait=True)\n",
        "        \n",
        "              print('Epoch: ', epoch_num + 1)\n",
        "              print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_labels) / batchsize, train_loss / (step_num + 1)))\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPZ0MZU06Xxu"
      },
      "source": [
        "gtp_clf = GTP2BinaryClassifier()\n",
        "gtp_clf = gtp_clf.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc6BBhJ_6gQL"
      },
      "source": [
        "# Configure the Padding token id\n",
        "gtp_clf.gtp2.config.pad_token_id = tokenizer.eos_token_id\n",
        "gtp_clf.train_m(train_tokens_ids,train_y,train_masks, EPOCHS, BATCH_SZ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIQXu7cL6n1g"
      },
      "source": [
        "**Evaluate on Testing Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpBPha-z6gyA"
      },
      "source": [
        "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).long()\n",
        "\n",
        "test_masks_tensor = torch.tensor(test_masks)\n",
        "\n",
        "\n",
        "test_dataset = TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=16)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QSujIkh6s79"
      },
      "source": [
        "# Evaluate Model\n",
        "gtp_clf.eval() # Define eval\n",
        "gpt_predicted = [] # Store Result\n",
        "with torch.no_grad():\n",
        "    for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "        token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "        # ----------------------------------------------------------------\n",
        "        outputs = gtp_clf.gtp2(token_ids,attention_mask=masks,labels=labels)\n",
        "        loss, logits = outputs[:2]\n",
        "        numpy_logits = logits.detach().cpu().numpy()\n",
        "        # ----------------------------------------------------------------\n",
        "        gpt_predicted +=list(numpy_logits.argmax(axis=-1).flatten().tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke386Aoj6xXG"
      },
      "source": [
        "print_performance('GPT2',test_y, gpt_predicted)\n",
        "\n",
        "# Recording TPR and FPR for the TESTING-ROC curves\n",
        "GPT_test = {}\n",
        "GPT_test['fpr'], GPT_test['tpr'], thresh = roc_curve(test_y, gpt_predicted)\n",
        "GPT_test['auc'] = roc_auc_score(test_y, gpt_predicted) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5t8JqbTG1qm"
      },
      "source": [
        "write_to_file(\"stide-pm.txt\", GPT_test, 'GPT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJgQwUXi62OA"
      },
      "source": [
        "# Ploting the overlaid ROC curves on testing results:\n",
        "graph_multi_ROC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-KVm3qLDNsk"
      },
      "source": [
        "# **Write performance measures to file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CIEcZ4ke9k1"
      },
      "source": [
        "# Save performance measure dict of each model to a file\n",
        "def write_to_file (varname, model_name):\n",
        "  clean_status = 'clean' if CLEAN else 'unclean'\n",
        "  filename = DATA +'-'+ str(SEQ_WINDOW) +'-'+ clean_status + \".txt\"\n",
        "  file = open(filename, \"a\")\n",
        "  str_dictionary = repr(varname)\n",
        "  file.write(\"{}_test = \".format(model_name) + str_dictionary + \"\\n\")\n",
        "  file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uusevnMCe9kO"
      },
      "source": [
        "write_to_file(BERT_test, 'BERT')\n",
        "write_to_file(GPT_test, 'GPT')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}