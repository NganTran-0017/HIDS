{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NganTran-0017/HIDS/blob/main/ML_HIDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "837EJx8fFz8O"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_IP76v1DNX1"
      },
      "source": [
        "Update remove duplicate between train and test --> create independent test\n",
        "check why test set after removing the intersection (aka independent test) has no frequent record? --> no, set(independent test) has fewer records than independent test.\n",
        "So the previous clean_data method removes duplication and overlap instances, while the new method (remove_duplicate) only removes overlap instance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1zufIrelKfl"
      },
      "source": [
        "!rm *.txt\n",
        "! rm *.int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "baLX852RsM7a"
      },
      "outputs": [],
      "source": [
        "#@title Specify parameters before running\n",
        "\n",
        "\n",
        "SZ =  1#@param {type:\"number\"}         # Indicate a fraction number to sample train set when it's too big. Located in Data Partition\n",
        "\n",
        "SEQ_WINDOW =  25#@param {type:\"integer\"} # Indicate the window length to parse the sequence into. Used in Data Parsing section\n",
        "\n",
        "BATCH_SZ =  32#@param {type:\"integer\"} # Indicate the window length to parse the sequence into. Used in Data Parsing section\n",
        "\n",
        "EPOCHS =  2#@param {type:\"integer\"} # Indicate the window length to parse the sequence into. Used in Data Parsing section\n",
        "\n",
        "# Indicate to clean data or not. Used in Data Cleaning section\n",
        "CLEAN = True #@param {type:\"boolean\"}\n",
        "DATA = \"Live-Named\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dDDU0UkRplxK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score, roc_curve, auc, recall_score, precision_score,plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "\n",
        "#import nltk\n",
        "#nltk.download(\"popular\")\n",
        "## Tokenizing syscall sequences into n-grams of 6\n",
        "#from nltk.tokenize import word_tokenize\n",
        "#from nltk import ngrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-0vzrcTekD3"
      },
      "source": [
        "## **Preparing data for data partition**\n",
        "- Combine data and labels together. \n",
        "- Combine data from each class together --> Create a pool of data \n",
        "- Split data pool into train and test\n",
        "\n",
        "## **Cleaning**\n",
        "- Remove dupplication between train and test\n",
        "\n",
        "- 2 directions for Testing set:\n",
        "  *  Test with clean data: Remove overlap and dupplication between Normal and Intrusion in Test data\n",
        "  *  Test with Unclean data: Leave Test data as is\n",
        "\n",
        "- 2 directions Training set:\n",
        "  *   Clean model: Remove overlap and dupplication between Normal and Intrusion in Train data\n",
        "  *   Unclean model: Leave Train data as is\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0zdh0uv7td8"
      },
      "source": [
        "#**Load partitioned data from here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "i-xogDDy0UH6",
        "outputId": "2dab14d6-a90c-469a-cad6-57f4920db393"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8aaffc37-6437-4909-bd35-a9c77d3c23b7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8aaffc37-6437-4909-bd35-a9c77d3c23b7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_clean.csv to test_clean.csv\n",
            "Saving test_unclean.csv to test_unclean.csv\n",
            "Saving train.csv.gz to train.csv.gz\n",
            "Saving train_clean.csv to train_clean.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RklkD0pv0fKo"
      },
      "outputs": [],
      "source": [
        "# Read in data\n",
        "if CLEAN:   x_train = pd.read_csv('train_clean.csv', header = 0)\n",
        "else:       x_train = pd.read_csv('train.csv.gz', header = 0, compression = 'gzip')\n",
        "test_clean = pd.read_csv('test_clean.csv', header = 0)\n",
        "test_unclean = pd.read_csv('test_unclean.csv', header = 0)\n",
        "\n",
        "x_train.rename(columns = {'25': 'Label'}, inplace = True)\n",
        "test_clean.rename(columns = {'25': 'Label'}, inplace = True)\n",
        "test_unclean.rename(columns={'25':'Label'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "MiXTRs30sbKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_clean"
      ],
      "metadata": {
        "id": "nCXyfCmNuDpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg9M0umdr1if"
      },
      "outputs": [],
      "source": [
        "# SZ proportion is used when duplicated training data is not removed and the training sz is too big\n",
        "\n",
        "#x_train['Label'] = y_train\n",
        "#x_train = x_train.sample(frac= SZ) # Shuffle data with a SZ proportion\n",
        "#x_train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Separate data and label\n",
        "y_train = x_train['Label']\n",
        "x_train.drop(columns='Label', inplace=True)\n",
        "\n",
        "y_test_clean = test_clean['Label']\n",
        "test_clean.drop(columns = 'Label', inplace=True)\n",
        "\n",
        "y_test_unclean = test_unclean['Label']\n",
        "test_unclean.drop(columns = 'Label', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QifC28hb0eUK"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN8DfkURmD8X"
      },
      "source": [
        " ## **Clean Train**\n",
        " Remove rows that exist in both normal and intrusion and rows that frequently appear within each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G2--bme1Iue"
      },
      "outputs": [],
      "source": [
        "## Get % of duplicates in both datasets\n",
        "\n",
        "# Convert normal df to set, and intrusion df to set\n",
        "def clean_data(normal, intrusion):\n",
        "  normal_list = normal.values.tolist()\n",
        "  intrusion_list = intrusion.values.tolist()\n",
        "  normal_set = set(tuple(i) for i in normal_list)\n",
        "  intrusion_set = set(tuple(i) for i in intrusion_list)\n",
        "  print('List sz vs. Set sz of normal sequences: %d vs. %d'% (len(normal_list),len(normal_set)) )\n",
        "  print('List sz vs. Set sz of intrusion sequences: %d vs. %d'% (len(intrusion_list),len(intrusion_set)) )\n",
        "    \n",
        "  normal_dupplication = (len(normal_list) - len(normal_set)) /len(normal_list)*100 \n",
        "  intrusion_duplication = (len(intrusion_list)-len(intrusion_set))/len(intrusion_list) * 100\n",
        "\n",
        "  print('Duplication Rate in Normal Class: %.3f%%'% normal_dupplication )\n",
        "  print('Duplication Rate in Intrusion Class: %.3f%%'% intrusion_duplication) \n",
        " \n",
        "  c_intrusion = intrusion_set - normal_set \n",
        "  overlap_rate =  len(normal_set.intersection(intrusion_set)) / len(normal_set.union(intrusion_set)) * 100\n",
        "  print('Overlap rate: %.3f%%' % overlap_rate)\n",
        "  \n",
        "  #c_normal = normal_set - intrusion_set\n",
        "  if len(c_intrusion) == 0:\n",
        "    print(DATA+' No Duplication!')\n",
        "  if len(c_intrusion) > 0:\n",
        "    intrusion = pd.DataFrame(c_intrusion)\n",
        "  else:\n",
        "    intrusion = pd.DataFrame(intrusion_set)\n",
        "  #if len(c_normal) > 0:\n",
        "  #  normal = pd.DataFrame(c_normal)\n",
        "  #else:\n",
        "  normal = pd.DataFrame(normal_set)\n",
        "\n",
        "  print('After cleaning: \\nNormal sz:', len(normal), ' Intrusion sz:', len(c_intrusion) )\n",
        "  return normal, intrusion\n",
        "\n",
        "\n",
        "# If the CLEAN parameter at the top is checked, we'll train the model with clean data\n",
        "if CLEAN:\n",
        "  filt = y_train == 0\n",
        "  train_normal = x_train.loc[filt]\n",
        "  train_intrusion = x_train.loc[~filt]\n",
        "  normal, intrusion = clean_data(train_normal, train_intrusion) # clean normal and intrusion in Train \n",
        "\n",
        "  normal['Label'] = 0; intrusion['Label'] = 1\n",
        "  x_train = normal.append(intrusion, ignore_index = True)\n",
        "  x_train = x_train.sample(frac = 1)\n",
        "  x_train.reset_index(drop=True, inplace = True)\n",
        "  y_train = x_train['Label']\n",
        "  x_train.drop(columns = 'Label', inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRFmq3j-l0qw"
      },
      "outputs": [],
      "source": [
        "#x_train['Label'] = y_train\n",
        "#x_train.to_csv('train_clean.csv', index=False)\n",
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inEFCUES885H"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ7j7n01sZE1"
      },
      "source": [
        "If there is not enough data from either class, bootstrap to generate more data and create a balanced sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAes54Ws83R4"
      },
      "outputs": [],
      "source": [
        "#filt = y_train == 0\n",
        "#normal_train = x_train.loc[filt]\n",
        "#normal_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNxhZnUm9fm6"
      },
      "outputs": [],
      "source": [
        "#intrusion_train = x_train.loc[~filt]\n",
        "#intrusion_train\n",
        "\n",
        "# Separate normal and intrusion in Test Clean so that I can call func clean_data on them\n",
        "def separate_two_classes (data, label):\n",
        "  ## Filter normal data from Test and drop label column\n",
        "  filt = label == 0\n",
        "  normal_class = data.loc[filt]\n",
        "  #normal_class.drop(columns = 'Label', inplace = True)\n",
        "\n",
        "  ## Filter Intrusion data from Test and drop label column\n",
        "  intrusion_class = data.loc[~filt]\n",
        "  #intrusion_class.drop(columns = 'Label', inplace = True)\n",
        "  return normal_class, intrusion_class\n",
        "\n",
        "normal_train, intrusion_train = separate_two_classes(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7NZyzbVcNTk"
      },
      "outputs": [],
      "source": [
        "# Bootstrap training data\n",
        "\n",
        "## Lived-name has more intrusion cases than normal cases (189 > 71) --> bootstrap normal cases only\n",
        "x_train['Label'] = y_train\n",
        "if len(intrusion_train) > len(normal_train):\n",
        "  x_train = x_train.iloc[intrusion_train.index].append(x_train.iloc[normal_train.index].sample(n = len(intrusion_train), replace=True), ignore_index=True) #upsampled normal data and add to train set\n",
        "else:\n",
        "  x_train = x_train.iloc[normal_train.index].append(x_train.iloc[intrusion_train.index].sample(n = len(normal_train), replace=True), ignore_index=True) #upsampled intrusion data and add to train set\n",
        "\n",
        "#x_train = x_train.append(x_train.sample(frac=1), ignore_index=True) # Bootstrap training data in case there is not enough data\n",
        "x_train = x_train.sample(frac= SZ) # Shuffle data with a SZ proportion\n",
        "x_train.reset_index(drop=True, inplace=True)\n",
        "y_train = x_train['Label']\n",
        "x_train.drop(columns='Label', inplace=True)\n",
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnDDh0TWsyS7"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVoazZKmYGtc"
      },
      "outputs": [],
      "source": [
        "test_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axzgGA4SYLIA"
      },
      "outputs": [],
      "source": [
        "test_unclean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0UCA-ZuXHX_"
      },
      "source": [
        "\n",
        "# **Performance Measures**\n",
        "\n",
        "\n",
        "1.   Function calc_false_positive: Calculates FPR\n",
        "2.   Function print_performance: Formats printing performance metrics and ROC curve for each model\n",
        "3.   Function color_confusion_matrix: prints out a heatmap of confusion matrix in blue color scale\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA1PZX4XBNLO"
      },
      "outputs": [],
      "source": [
        "# This function calculate False Positive Rate given a confusion matrix\n",
        "def calc_false_positive (cmatrix):\n",
        "  specificity = cmatrix[0,0]/(cmatrix[0,0] + cmatrix[0,1])\n",
        "  return 1-specificity\n",
        "\n",
        "# This function prints performance metrics and ROC curve given the model name, true labels and predicted labels\n",
        "def print_performance( model_name, true_labels, pred_labels):\n",
        "  # rows are actual, columns are predicted\n",
        "  cmatrix = confusion_matrix(true_labels, pred_labels)\n",
        "  fpr = calc_false_positive(cmatrix)\n",
        "\n",
        "  print('Confusion Matrix: \\n',cmatrix)\n",
        "  print('\\nTesting Accuracy: %.2f'% metrics.accuracy_score(true_labels, pred_labels))\n",
        "  print('Precision:%.2f'%  metrics.precision_score(true_labels, pred_labels))\n",
        "  print('Recall: %.2f'% metrics.recall_score(true_labels, pred_labels))\n",
        "  print('False Positive Rate: %.2f'% fpr)\n",
        "  print('\\nClassification report:', classification_report(true_labels, pred_labels), sep='\\n')\n",
        "  print('AUC: %.2f'% roc_auc_score(true_labels, pred_labels))\n",
        "\n",
        "  false_positive_rate, recall, thresholds = roc_curve(true_labels, pred_labels)\n",
        "  roc_auc = auc(false_positive_rate, recall)\n",
        "  plt.figure()\n",
        "  if CLEAN: clean_status='Clean '\n",
        "  else: clean_status ='Overlapped and Duplicated '\n",
        "  plt.title( model_name+' ROC Curve on '+ clean_status + DATA + ' with Seq Len of '+ str(SEQ_WINDOW))\n",
        "  plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.2f' %roc_auc)\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.plot([0,1], [0,1], 'r--')\n",
        "  plt.xlim([0.0,1.0])\n",
        "  plt.ylim([0.0,1.1])\n",
        "  plt.ylabel('Recall')\n",
        "  plt.xlabel('False Positive Rate (1-Specificity)')\n",
        "  #plt.savefig(model_name+'-ROC.jpg')\n",
        "  plt.show()\n",
        "\n",
        "# Plot a heatmap of confusion matrix given the model name, a classifier model, testing data and the predicted label\n",
        "def color_confusion_matrix( model_name, model, x_test, y_test, y_predicted):\n",
        "  class_names = ['Normal', 'Intrusion']\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(6, 6))\n",
        "  plot_confusion_matrix(model, x_test, y_test, display_labels=class_names, \n",
        "                        values_format='d', ax = ax, cmap=plt.cm.Blues)\n",
        "  plt.title('Confusion Matrix of ' + str(model_name))\n",
        "  #plt.savefig(model_name+'-CM.jpg')\n",
        "  plt.show()\n",
        "\n",
        "  cmatrix = confusion_matrix(y_test, y_predicted)\n",
        "  print(cmatrix)\n",
        "\n",
        "\n",
        "# Save performance measure dict of each model to a file\n",
        "def write_to_file (varname, model_name, clean):\n",
        "  clean_status = 'clean' if CLEAN else 'unclean'\n",
        "  filename = DATA +'-'+ str(SEQ_WINDOW) +'-'+ clean_status + \"-model.txt\"\n",
        "  file = open(filename, \"a\")\n",
        "  str_dictionary = repr(varname)\n",
        "  file.write(\"{}_test_{} = \".format(model_name, clean) + str_dictionary + \"\\n\")\n",
        "  file.close()\n",
        "\n",
        "# This func takes in Test sets to evaluate model. Make it convenient when testing with clean and unclean data\n",
        "def test_model(data, label, model, model_name, clean):\n",
        "  if model_name == 'NN':\n",
        "    y_predicted = np.argmax(model.predict(data), axis=-1)\n",
        "  else:\n",
        "    y_predicted = model.predict(data)\n",
        "\n",
        "  print('--------------------' + model_name + ' on ' + clean + ' data --------------------')\n",
        "  print_performance(model_name, label, y_predicted)\n",
        "\n",
        "  # Recording TPR and FPR for the TESTING ROC curves\n",
        "  performance = {}\n",
        "  performance['fpr'], performance['tpr'], thresh = roc_curve(label, y_predicted)\n",
        "  performance['auc'] = roc_auc_score(label, y_predicted)\n",
        "  print('Test AUC: %.3f' %(performance['auc']))\n",
        "\n",
        "  return performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-keFefagnSl"
      },
      "source": [
        "# **K-means**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0DPPwlWKeoA"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "# Choose K cluster = 2\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "# Fit Kmeans to the training set\n",
        "kmeans.fit(x_train)\n",
        "\n",
        "# Number of iterations before converging\n",
        "print('Number of iterations before converging:', kmeans.n_iter_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbLcjt6vF8aU"
      },
      "outputs": [],
      "source": [
        "## TESTING K-MEANS with clean data and unclean data\n",
        "KM_clean_perf   = test_model(test_clean, y_test_clean, kmeans, 'KM', 'clean'); print('\\n\\n')\n",
        "KM_unclean_perf = test_model(test_unclean, y_test_unclean, kmeans, 'KM', 'unclean')\n",
        "\n",
        "write_to_file(KM_clean_perf, 'KM', 'clean')\n",
        "write_to_file(KM_unclean_perf, 'KM', 'unclean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKMnutnOgsZ5"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk83mqk_fC9k"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Fit the model on the training set\n",
        "lgModel = LogisticRegression().fit(x_train, y_train)\n",
        "\n",
        "## TESTING Logistic Regression with clean data and unclean data\n",
        "LR_clean_perf   = test_model(test_clean, y_test_clean, lgModel, 'LR', 'clean'); print('\\n\\n')\n",
        "LR_unclean_perf = test_model(test_unclean, y_test_unclean, lgModel, 'LR', 'unclean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrbnifXmGB3W"
      },
      "outputs": [],
      "source": [
        "# Save performance to text file\n",
        "write_to_file(LR_clean_perf, 'LR', 'clean')\n",
        "write_to_file(LR_unclean_perf, 'LR', 'unclean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boOPLuv1zl0p"
      },
      "source": [
        "# **SVM**\n",
        "\n",
        "This model uses a Polynomial kernel, and the rest of the parameters are as default\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6zM_WRNH74s"
      },
      "outputs": [],
      "source": [
        "if len(x_train) > 500000: \n",
        "  svm_sz = 0.05  \n",
        "elif len(x_train) > 100000:\n",
        "  svm_sz = 0.2\n",
        "else:\n",
        "  svm_sz = 1\n",
        "\n",
        "svm_sz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrM4M1TZEpvK"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data = x_train.copy(deep=True) # create a deep copy of x_train, so any modification to train_data won't affect x_train\n",
        "train_data['Label'] = y_train\n",
        "train_data = train_data.groupby('Label').sample(frac = svm_sz)\n",
        "train_data.reset_index(drop=True, inplace= True)\n",
        "#train_data\n",
        "svm_x_train = train_data.drop(columns='Label')\n",
        "svm_y_train = train_data['Label']\n",
        "svm_x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "383ioOTmI5-u"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "#### Create a SVM classifier using polynomial Kernel\n",
        "print('\\n****Polynomial kernel model: ')\n",
        "svm_model = svm.SVC(kernel = 'poly')\n",
        "\n",
        "#Train the  & Get accuracy from training\n",
        "svm_model.fit(svm_x_train, svm_y_train)\n",
        "\n",
        "## TESTING SVM with clean data and unclean data\n",
        "SVM_clean_perf   = test_model(test_clean,   y_test_clean,   svm_model, 'SVM', 'clean'); print('\\n\\n')\n",
        "SVM_unclean_perf = test_model(test_unclean, y_test_unclean, svm_model, 'SVM', 'unclean')\n",
        "\n",
        "# Save performance to text file\n",
        "write_to_file(SVM_clean_perf, 'SVM', 'clean')\n",
        "write_to_file(SVM_unclean_perf, 'SVM', 'unclean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKSizyx2J1-0"
      },
      "source": [
        " Plot a heatmap confusion matrix\n",
        "color_confusion_matrix('SVM', svm_model, x_test, y_test, y_predicted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyAknSAkQ3be"
      },
      "source": [
        "# **Neural Net**\n",
        "\n",
        "This model contains 3 layers: input layer of 6 nodes, a fully connected layer of 6 nodes and an output layer of 2 nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USe11YPvQ3bf"
      },
      "outputs": [],
      "source": [
        "# Scale syscall number to between 0 and 1\n",
        "# The maximum syscall number in UNM data is 181\n",
        "max_syscall = 181\n",
        "x_train_nn = x_train/max_syscall\n",
        "clean_x_test_nn = test_clean/max_syscall\n",
        "unclean_x_test_nn =  test_unclean/max_syscall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuOUNJieQ3bg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "INPUT_SZ = len(x_train.columns)\n",
        "nn_model = keras.Sequential([\n",
        "    keras.layers.Input(shape = (INPUT_SZ,)),           # model expect input to be a vector of 6 numbers\n",
        "    keras.layers.Dense(INPUT_SZ, activation = 'relu'), \n",
        "    keras.layers.Dense(2, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "nn_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model to training set\n",
        "history = nn_model.fit(x_train_nn, y_train, epochs=10, batch_size= 32, verbose=1)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGUvRkXUjo3K"
      },
      "outputs": [],
      "source": [
        "# Get predicted Training labels\n",
        "#y_pred = np.argmax(nn_model.predict(x_train_nn), axis=-1)\n",
        "\n",
        "## TESTING NN with clean data and unclean data\n",
        "NN_clean_perf   = test_model(clean_x_test_nn,   y_test_clean,   nn_model, 'NN', 'clean'); print('\\n\\n')\n",
        "NN_unclean_perf = test_model(unclean_x_test_nn, y_test_unclean, nn_model, 'NN', 'unclean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mehetMzFUBrt"
      },
      "outputs": [],
      "source": [
        "nn_model.summary()\n",
        "\n",
        "#history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uN0pWMBuGN3_"
      },
      "outputs": [],
      "source": [
        "# Save performance to text file\n",
        "write_to_file(NN_clean_perf, 'NN', 'clean')\n",
        "write_to_file(NN_unclean_perf, 'NN', 'unclean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eak45tL1s7AT"
      },
      "source": [
        "# **Decision Tree**\n",
        "\n",
        "This model uses GINI criterion to split the data and requires at least 10 observations to split and 5 observations in the leaf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_mhdZxSs6Z5"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create and Train DecTree model\n",
        "decTree = DecisionTreeClassifier(criterion='gini', min_samples_split=10,min_samples_leaf=5,max_features='auto')\n",
        "decTree = decTree.fit(x_train, y_train)\n",
        "\n",
        "## TESTING DT with clean data and unclean data\n",
        "DT_clean_perf   = test_model(test_clean,   y_test_clean,   decTree, 'DT', 'clean'); print('\\n\\n')\n",
        "DT_unclean_perf = test_model(test_unclean, y_test_unclean, decTree, 'DT', 'unclean')\n",
        "\n",
        "# Save performance to text file\n",
        "write_to_file( DT_clean_perf, 'DT', 'clean')\n",
        "write_to_file( DT_unclean_perf, 'DT', 'unclean')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOGaush6RBtf"
      },
      "source": [
        "# **Random Forest**\n",
        "\n",
        "This model has no max depth and allows bootstrapping observations during training. It uses GINI criterion to split and requires a minimum of 10 observations to split and the leaf node must have above 5 observations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-g6W8k4k_A3"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Build model\n",
        "randomForest = RandomForestClassifier(max_depth=None, min_samples_split=10, min_samples_leaf=5, \n",
        "                                      max_features='auto', bootstrap=True,verbose=0, criterion='gini')\n",
        "# Train the model with training set\n",
        "randomForest.fit(x_train, y_train)\n",
        "\n",
        "## TESTING RF with clean data and unclean data\n",
        "RF_clean_perf   = test_model(test_clean,   y_test_clean,   randomForest, 'RF', 'clean'); print('\\n\\n')\n",
        "RF_unclean_perf = test_model(test_unclean, y_test_unclean, randomForest, 'RF', 'unclean')\n",
        "\n",
        "\n",
        "# Save performance to text file\n",
        "write_to_file( RF_clean_perf, 'RF', 'clean')\n",
        "write_to_file( RF_unclean_perf, 'RF', 'unclean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doGliXotvRgg"
      },
      "source": [
        "# **KNN**\n",
        "\n",
        "This model classifies each observation based on 3 nearest neighbors with uniform weight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHH_-Veot_FD"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Creat and Train KNN model\n",
        "KNN = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
        "KNN.fit(svm_x_train, svm_y_train)\n",
        "\n",
        "# Recording TPR and FPR for the TRAINING ROC curves\n",
        "#y_pred = KNN.predict(x_train)\n",
        "#KNN_train = {}\n",
        "#KNN_train['fpr'], KNN_train['tpr'], thresh = roc_curve(y_train, y_pred)\n",
        "#KNN_train['auc'] = roc_auc_score(y_train, y_pred)\n",
        "\n",
        "\n",
        "## TESTING KNN with clean data and unclean data\n",
        "KNN_clean_perf   = test_model(test_clean,   y_test_clean,   KNN, 'KNN', 'clean'); print('\\n\\n')\n",
        "KNN_unclean_perf = test_model(test_unclean, y_test_unclean, KNN, 'KNN', 'unclean')\n",
        "\n",
        "# Save performance to text file\n",
        "write_to_file( KNN_clean_perf, 'KNN', 'clean')\n",
        "write_to_file( KNN_unclean_perf, 'KNN', 'unclean')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv2CQsOUxLSv"
      },
      "source": [
        "# **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCLL6xLRwU1s"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Create a Gaussian Naive Bayes classifier and train with training set\n",
        "NaiveBayes = GaussianNB()\n",
        "NaiveBayes.fit(x_train, y_train)\n",
        "\n",
        "# Recording TPR and FPR for the TRAINING ROC curves\n",
        "#y_pred = NaiveBayes.predict(x_train)\n",
        "#NB_train = {}\n",
        "#NB_train['fpr'], NB_train['tpr'], thresh = roc_curve(y_train, y_pred)\n",
        "#NB_train['auc'] = roc_auc_score(y_train, y_pred)\n",
        "\n",
        "\n",
        "## TESTING KNN with clean data and unclean data\n",
        "NB_clean_perf   = test_model(test_clean,   y_test_clean,   NaiveBayes, 'NB', 'clean'); print('\\n\\n')\n",
        "NB_unclean_perf = test_model(test_unclean, y_test_unclean, NaiveBayes, 'NB', 'unclean')\n",
        "\n",
        "\n",
        "# Save performance to text file\n",
        "write_to_file(NB_clean_perf, 'NB', 'clean')\n",
        "write_to_file(NB_unclean_perf, 'NB', 'unclean')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P6CLgj6LxLzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtoZZkWd8e-a"
      },
      "source": [
        "# **End**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbdIi8KvCDCS"
      },
      "outputs": [],
      "source": [
        "def plot_ROC_Clean_Unclean(clean, unclean, model_name):\n",
        "  colors = {'unclean': 'lightcoral','clean': 'blue'}\n",
        "\n",
        "  plt.plot(clean.get('fpr'), clean.get('tpr'), color=colors.get('clean'),  label= \"AUC on Clean Data =\" + str( round(clean.get('auc'), 3) ) )   \n",
        "  plt.plot(unclean.get('fpr'), unclean.get('tpr'), color=colors.get('unclean'),  label= \"AUC on Unclean Data =\" + str( round(unclean.get('auc'), 3) ) )   \n",
        "  plt.title(model_name +' Performance on Clean and Unclean Data')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "plot_ROC_Clean_Unclean(KM_clean_perf, KM_unclean_perf, 'KM')\n",
        "plot_ROC_Clean_Unclean(LR_clean_perf, LR_unclean_perf, 'LR')\n",
        "plot_ROC_Clean_Unclean(SVM_clean_perf, SVM_unclean_perf, 'SVM')\n",
        "plot_ROC_Clean_Unclean(NN_clean_perf, NN_unclean_perf, 'NN')\n",
        "plot_ROC_Clean_Unclean(DT_clean_perf, DT_unclean_perf, 'DT')\n",
        "plot_ROC_Clean_Unclean(RF_clean_perf, RF_unclean_perf, 'RF')\n",
        "plot_ROC_Clean_Unclean(KNN_clean_perf, KNN_unclean_perf, 'KNN')\n",
        "plot_ROC_Clean_Unclean(NB_clean_perf, NB_unclean_perf, 'NB')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JELKYpJHFJD"
      },
      "source": [
        "# Graphing overlaid ROC curves, where each one represents a model AUC score\n",
        "def graph_multi_ROC (DATA, SEQ_LEN, CLEAN ):\n",
        "  # Set color for each model\n",
        "  colors = {'KM': 'lightcoral','LR': 'darkorange', 'SVM':'lime', 'NB': 'steelblue',\n",
        "            'NN': 'purple','DT': 'magenta','RF': 'deeppink','KNN': 'darkturquoise',\n",
        "            'BERT': 'darkred', 'GPT': 'blue'}\n",
        "  # Set marker for each model          \n",
        "  markers = {'KM':'1--','LR': 'v--', 'SVM': '^--', 'NN': '*--', 'DT': 'o--', 'RF': '+--', 'KNN': '.--', 'NB': 'x--', 'BERT':'<--', 'GPT': '>--'}\n",
        "  \n",
        "  plt.figure(figsize=(9,6))\n",
        "\n",
        "  plt.plot(KM_test.get('fpr'), KM_test.get('tpr'), markers.get('KM'), color=colors.get('KM'),  label=\"KM - AUC=\" + str( round(KM_test.get('auc'), 3) ) )   \n",
        "  plt.plot(LR_test.get('fpr'), LR_test.get('tpr'), markers.get('LR'), color=colors.get('LR'),  label=\"LR - AUC=\" + str( round(LR_test.get('auc'),3) ) )\n",
        "  plt.plot(SVM_test.get('fpr'),SVM_test.get('tpr'),markers.get('SVM'),color=colors.get('SVM'), label=\"SVM - AUC=\"+ str( round(SVM_test.get('auc'), 3) ) )\n",
        "  plt.plot(NN_test.get('fpr'), NN_test.get('tpr'), markers.get('NN'), color=colors.get('NN'),  label=\"NN - AUC=\" + str( round(NN_test.get('auc'), 3) ) )\n",
        "  plt.plot(DT_test.get('fpr'), DT_test.get('tpr'), markers.get('DT'), color=colors.get('DT'),  label=\"DT - AUC=\" + str( round(DT_test.get('auc'), 3) ) )\n",
        "  plt.plot(RF_test.get('fpr'), RF_test.get('tpr'), markers.get('RF'), color=colors.get('RF'),  label=\"RF - AUC=\" + str( round(RF_test.get('auc'), 3) ) )\n",
        "  plt.plot(KNN_test.get('fpr'),KNN_test.get('tpr'),markers.get('KNN'),color=colors.get('KNN'), label=\"KNN - AUC=\"+ str( round(KNN_test.get('auc'), 3) ) )\n",
        "  plt.plot(NB_test.get('fpr'), NB_test.get('tpr'), markers.get('NB'), color=colors.get('NB'),  label=\"NB - AUC=\" + str( round(NB_test.get('auc'), 3) ) )\n",
        "  try:\n",
        "    plt.plot(BERT_test.get('fpr'),BERT_test.get('tpr'), markers.get('BERT'), color=colors.get('BERT'),  label=\"BERT - AUC=\"+ str(BERT_test.get('auc').round(3)))\n",
        "    plt.plot(GPT_test.get('fpr'),GPT_test.get('tpr'), markers.get('GPT'), color=colors.get('GPT'),  label=\"GPT-2 - AUC=\"+ str(GPT_test.get('auc').round(3)))\n",
        "  except NameError:\n",
        "    print('\\nBERT_test and GPT_test do not exist\\n')\n",
        "\n",
        "  plt.plot([0,1], [0,1], 'k--', label='Random Chances')\n",
        "  plt.xlim([0.0,1.0])\n",
        "  plt.ylim([0.0,1.02])\n",
        "  plt.ylabel('Recall')\n",
        "  plt.xlabel('False Positive Rate (1-Specificity)')\n",
        "  plt.legend(loc='lower right') \n",
        "  plt.title( 'Testing ROCs %s on %s with seq len of %d' % (CLEAN, DATA, SEQ_LEN) )\n",
        "  #plt.savefig(DATA_I+'-'+train_or_test+'.jpg', dpi = 80)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Func load_dict loads the dictionary contents extracted from the text file to a given variable name (stored in varname str)\n",
        "# Output is a global dict variable \n",
        "# Input format:\n",
        "## varname: a string of variable name\n",
        "## dictvar: a dict containing the dictionary contents extracted from the text file\n",
        "def load_dict(varname, dictvar):\n",
        "  exec('%s = {}' %(varname), globals() )\n",
        "  for key, value in dictvar.items():\n",
        "    #print(key,\":\", value)\n",
        "    exec('%s[%s] = %s' % (varname, key, value), globals())\n",
        "\n",
        "# Func localFile extract the contents of each dictionary variables and load them into a dictionary\n",
        "# Output: All the dictionaries from the text file will be loaded to the program\n",
        "#  Input format: a text file containing multiple dictionaries, where each dict has this format:\n",
        "## KM_test = {'fpr': array([0.        , 0.86136255, 1.        ]), 'tpr': array([0.        , 0.49007655, 1.        ]), 'auc': 0.31435699935689737}\n",
        "## This function reads in each line, process the string and load it as a dict variable\n",
        "## In the end, this function loads global variables based on each line of text\n",
        "def load_dict_from_text (localFile):\n",
        "  with open(localFile) as infile_object : \n",
        "    lines = infile_object.read().splitlines()    # Open and read each line\n",
        "    measures = {}                                # stores elements of a dict\n",
        "  for line in lines: \n",
        "    words = line.strip(\"\\n \").split(' = ')     # remove whitespace and split str to get var name. words[0] contains var name, words[1] contains the phrase that goes after '='\n",
        "    values = words[1].strip(\" {} \").split('), ') # remove the whitespace and '{}', then split the second part of words to get each element in dict\n",
        "    # iterate through each key-value pairelement and process them to get specific key-value pair\n",
        "    for v in values:  \n",
        "      elements = v.split(': ')                   # split key value pair by ':'. elements[0] is key, elements[1] is value\n",
        "      elements[1] = elements[1].strip('array(')  # remove 'array(' from the value\n",
        "      #print(elements[0]) print(elements[1])\n",
        "      measures[ elements[0] ] = elements[1]      # save the key-value pairs found in a line into measures dict\n",
        "\n",
        "    load_dict(words[0], measures)                # load the content of measures dict into the variable name stored in words[0]\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-Crmv3vvtmy"
      },
      "outputs": [],
      "source": [
        "       \n",
        "#fileName = 'MIT Live Lpr-pm.txt'\n",
        "#load_dict_from_text(fileName)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhrPdS3wx-nB"
      },
      "source": [
        "clean_status = 'clean' if CLEAN else 'unclean'\n",
        "graph_multi_ROC(DATA, SEQ_WINDOW, clean_status)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQNi0zQY7QYT"
      },
      "source": [
        "## **Note**\n",
        "\n",
        "Synthetic Sendmail dataset contains some sequences with only 6 system calls. Therefore we padded on the right with -1 on these small sequences, so that the sequence length can be 15.\n",
        "After cleaning, there are 2021 unique normal sequences, while there are 423 unique intrusion sequences. This dataset is imbalanced. \n",
        "\n",
        "BERT and GPT significantly outperform the rest of the models with AUC above 0.95, while the others perform poorly on this dataset (AUC around 0.5)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZQNi0zQY7QYT"
      ],
      "name": "Latest Copy of ML-HIDS.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}