{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-Models-HIDS.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8GMYBPNarqFf",
        "-0UCA-ZuXHX_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NganTran-0017/HIDS/blob/main/DL_Models_HIDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mzc_frRBqSW"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baLX852RsM7a"
      },
      "source": [
        "#@title Specify parameters before running\n",
        "\n",
        "\n",
        "SZ =  1#@param {type:\"number\"}         # Indicate a fraction number to sample train set when it's too big. Located in Data Partition\n",
        "\n",
        "SEQ_WINDOW =  25#@param {type:\"integer\"} # Indicate the window length to parse the sequence into. Used in Data Parsing section\n",
        "\n",
        "BATCH_SZ =  16#@param {type:\"integer\"} # Indicate the window length to parse the sequence into. Used in Data Parsing section\n",
        "\n",
        "EPOCHS =  5#@param {type:\"integer\"} # Indicate the window length to parse the sequence into. Used in Data Parsing section\n",
        "\n",
        "# Indicate to clean data or not. Used in Data Cleaning section\n",
        "CLEAN = False #@param {type:\"boolean\"}\n",
        "DATA = \"Live-Lpr\" #@param {type:\"string\"}\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDDU0UkRplxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca40b61-41f0-4c00-f5e5-d2abefd329d2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score, roc_curve, auc, recall_score, precision_score,plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "\n",
        "## Tokenizing syscall sequences into n-grams of 6\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import ngrams"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TT_eMojSH4Qu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load pre-processed data**"
      ],
      "metadata": {
        "id": "fSPiWe98mFwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "IMh4u3wrmFhm",
        "outputId": "23d56b4b-ccb9-4139-89fc-174392cc2831"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-93578c6c-2b2b-47c8-b22a-42e79f599030\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-93578c6c-2b2b-47c8-b22a-42e79f599030\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in data\n",
        "x_train = pd.read_csv('train.csv', header = 0)\n",
        "test_clean = pd.read_csv('test_clean.csv', header = 0)\n",
        "test_unclean = pd.read_csv('test_unclean.csv', header = 0)\n"
      ],
      "metadata": {
        "id": "3FaUODSsmFf2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Separate data and label\n",
        "y_train = x_train['Label']\n",
        "x_train.drop(columns='Label', inplace=True)\n",
        "\n",
        "y_test_clean = test_clean['Label']\n",
        "test_clean.drop(columns = 'Label', inplace=True)\n",
        "\n",
        "y_test_unclean = test_unclean['Label']\n",
        "test_unclean.drop(columns ='Label', inplace=True)"
      ],
      "metadata": {
        "id": "eCDTcBAVVcZJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_unclean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "53vJsEi6mFdc",
        "outputId": "5315925b-cf30-4d8e-bf24-521a60369c04"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5419e083-3725-4cad-a0c6-3fe7218d2f93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>119</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>119</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>27</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>119</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>27</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>5</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>53</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>83</td>\n",
              "      <td>59</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>167</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>100</td>\n",
              "      <td>143</td>\n",
              "      <td>128</td>\n",
              "      <td>85</td>\n",
              "      <td>89</td>\n",
              "      <td>128</td>\n",
              "      <td>89</td>\n",
              "      <td>121</td>\n",
              "      <td>112</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>127</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>5</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>119</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105 rows Ã— 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5419e083-3725-4cad-a0c6-3fe7218d2f93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5419e083-3725-4cad-a0c6-3fe7218d2f93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5419e083-3725-4cad-a0c6-3fe7218d2f93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       0    1    2    3    4    5    6  ...   18   19   20   21   22   23   24\n",
              "0      4   56    7   56  119    2    3  ...    3    3    5   32   17    4    2\n",
              "1      3    3    3    3    3   56    7  ...  104  104  106  105  104  104  106\n",
              "2      3    3    3    3    3   56    7  ...  104  104  106  105  104  104  106\n",
              "3    106  105  104  104  106    9    9  ...   -1   -1   -1   -1   -1   -1   -1\n",
              "4    106  105  104  104  106    9    9  ...   -1   -1   -1   -1   -1   -1   -1\n",
              "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "100    5   56    7   56  119  119    3  ...    3    3    3    5    4    2   18\n",
              "101  106  105  104  104  106  105  104  ...   50   27    4   27   88  167  167\n",
              "102  100  143  128   85   89  128   89  ...    7   56  119  119    3    3   56\n",
              "103  104  106  105  104  104  106  105  ...   -1   -1   -1   -1   -1   -1   -1\n",
              "104    5   32   17    4    2    5    4  ...    3    2    3    2    5    3    3\n",
              "\n",
              "[105 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "FN2lx4dUHlM7",
        "outputId": "f9645410-485c-4885-8b72-4778033145ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f8daf68f-e092-47ef-bf04-d695289966a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>66</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>83</td>\n",
              "      <td>59</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>167</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>112</td>\n",
              "      <td>19</td>\n",
              "      <td>93</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>88</td>\n",
              "      <td>100</td>\n",
              "      <td>143</td>\n",
              "      <td>128</td>\n",
              "      <td>85</td>\n",
              "      <td>89</td>\n",
              "      <td>121</td>\n",
              "      <td>112</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>127</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>119</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245928</th>\n",
              "      <td>85</td>\n",
              "      <td>89</td>\n",
              "      <td>121</td>\n",
              "      <td>112</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>127</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>50</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245929</th>\n",
              "      <td>127</td>\n",
              "      <td>66</td>\n",
              "      <td>5</td>\n",
              "      <td>93</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>112</td>\n",
              "      <td>19</td>\n",
              "      <td>93</td>\n",
              "      <td>19</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>88</td>\n",
              "      <td>100</td>\n",
              "      <td>143</td>\n",
              "      <td>128</td>\n",
              "      <td>85</td>\n",
              "      <td>89</td>\n",
              "      <td>121</td>\n",
              "      <td>112</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>127</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245930</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>50</td>\n",
              "      <td>27</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245931</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>88</td>\n",
              "      <td>167</td>\n",
              "      <td>167</td>\n",
              "      <td>167</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>155</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245932</th>\n",
              "      <td>66</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>66</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>245933 rows Ã— 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8daf68f-e092-47ef-bf04-d695289966a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8daf68f-e092-47ef-bf04-d695289966a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8daf68f-e092-47ef-bf04-d695289966a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          0    1    2    3    4    5    6  ...   18   19   20   21   22   23   24\n",
              "0        45    4   27   66    5    4    2  ...  104  104  106  105  104  104  106\n",
              "1       104  104  106  105  104  104  106  ...   50   27    4   27   88  167  167\n",
              "2         5  112   19   93   19  100   50  ...  127    2   18    3    5   56    7\n",
              "3        56    7   56  119  119    3    3  ...   56  119    2    3    2    3    2\n",
              "4         2    3    2    3    2    3    2  ...    2    3    2    3    2    3    2\n",
              "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "245928   85   89  121  112    5   17    4  ...    3    3    3    3   32   50   27\n",
              "245929  127   66    5   93  100    5  112  ...  121  112    5   17    4  127    2\n",
              "245930    3    3    3    3   32   50   27  ...  106  105  104  104  106    9    9\n",
              "245931    2    2    5   50   27    4   27  ...    4   18    2    5  155    4   50\n",
              "245932   66    5   23   45    4   27   66  ...    5    5  105  104  104  106  105\n",
              "\n",
              "[245933 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "376udEA5GdPB"
      },
      "source": [
        " ## **Data Cleaning**\n",
        " Remove rows that exist in both normal and intrusion df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzvxq_ViJscy"
      },
      "source": [
        "## Get % of duplicates in both datasets\n",
        "\n",
        "# Convert normal df to set, and intrusion df to set\n",
        "def clean_data(normal, intrusion):\n",
        "  normal_list = normal.values.tolist()\n",
        "  intrusion_list = intrusion.values.tolist()\n",
        "  normal_set = set(tuple(i) for i in normal_list)\n",
        "  intrusion_set = set(tuple(i) for i in intrusion_list)\n",
        "  print('List sz vs. Set sz of normal sequences: %d vs. %d'% (len(normal_list),len(normal_set)) )\n",
        "  print('List sz vs. Set sz of intrusion sequences: %d vs. %d'% (len(intrusion_list),len(intrusion_set)) )\n",
        "    \n",
        "  normal_dupplication = (len(normal_list) - len(normal_set)) /len(normal_list)*100 \n",
        "  intrusion_duplication = (len(intrusion_list)-len(intrusion_set))/len(intrusion_list) * 100\n",
        "\n",
        "  print('Duplication Rate in Normal Class: %.3f%%'% normal_dupplication )\n",
        "  print('Duplication Rate in Intrusion Class: %.3f%%'% intrusion_duplication) \n",
        " \n",
        "  c_intrusion = intrusion_set - normal_set \n",
        "  overlap_rate =  len(normal_set.intersection(intrusion_set)) / len(normal_set.union(intrusion_set)) * 100\n",
        "  print('Overlap rate: %.3f%%' % overlap_rate)\n",
        "  \n",
        "  #c_normal = normal_set - intrusion_set\n",
        "  if len(c_intrusion) == 0:\n",
        "    print(DATA+' No Duplication!')\n",
        "  if len(c_intrusion) > 0:\n",
        "    intrusion = pd.DataFrame(c_intrusion)\n",
        "  else:\n",
        "    intrusion = pd.DataFrame(intrusion_set)\n",
        "  #if len(c_normal) > 0:\n",
        "  #  normal = pd.DataFrame(c_normal)\n",
        "  #else:\n",
        "  normal = pd.DataFrame(normal_set)\n",
        "\n",
        "  print('After cleaning: \\nNormal sz:', len(normal), ' Intrusion sz:', len(c_intrusion) )\n",
        "  return normal, intrusion"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztHCbJZ3Lsxq"
      },
      "source": [
        "# If the CLEAN parameter at the top is checked, we'll train the model with clean data\n",
        "if CLEAN:\n",
        "  filt = y_train == 0\n",
        "  train_normal = x_train.loc[filt]\n",
        "  train_intrusion = x_train.loc[~filt]\n",
        "  normal, intrusion = clean_data(train_normal, train_intrusion) # clean normal and intrusion in Train \n",
        "\n",
        "  normal['Label'] = 0; intrusion['Label'] = 1\n",
        "  x_train = normal.append(intrusion, ignore_index = True)\n",
        "  x_train = x_train.sample(frac = 1)\n",
        "  y_train = x_train['Label']\n",
        "  x_train.drop(columns = 'Label', inplace = True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filt = y_train == 0\n",
        "normal_train = x_train.loc[filt]\n",
        "normal_train\n",
        "\n",
        "intrusion_train = x_train.loc[~filt]\n",
        "intrusion_train"
      ],
      "metadata": {
        "id": "r_DQodRpIVKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bootstrap training data\n",
        "\n",
        "## Lived-name has more intrusion cases than normal cases (189 > 71) --> bootstrap normal cases only\n",
        "x_train['Label'] = y_train\n",
        "\n",
        "if len(intrusion_train) > len(normal_train):\n",
        "  x_train = x_train.iloc[intrusion_train.index].append(x_train.iloc[normal_train.index].sample(n = len(intrusion_train), replace=True), ignore_index=True) #upsampled normal data and add to train set\n",
        "else:\n",
        "  x_train = x_train.iloc[normal_train.index].append(x_train.iloc[intrusion_train.index].sample(n = len(normal_train), replace=True), ignore_index=True) #upsampled intrusion data and add to train set\n",
        "\n",
        "#x_train = x_train.append(x_train.sample(frac=1), ignore_index=True) # Bootstrap training data in case there is not enough data\n",
        "x_train = x_train.sample(frac= SZ) # Shuffle data with a SZ proportion\n",
        "x_train.reset_index(drop=True, inplace=True)\n",
        "y_train = x_train['Label']\n",
        "x_train.drop(columns='Label', inplace=True)\n",
        "x_train"
      ],
      "metadata": {
        "id": "yWVieVu6IaAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0UCA-ZuXHX_"
      },
      "source": [
        "\n",
        "# **Performance Measures**\n",
        "\n",
        "\n",
        "1.   Function calc_false_positive: Calculates FPR\n",
        "2.   Function print_performance: Formats printing performance metrics and ROC curve for each model\n",
        "3.   Function color_confusion_matrix: prints out a heatmap of confusion matrix in blue color scale\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA1PZX4XBNLO"
      },
      "source": [
        "# This function calculate False Positive Rate given a confusion matrix\n",
        "def calc_false_positive (cmatrix):\n",
        "  specificity = cmatrix[0,0]/(cmatrix[0,0] + cmatrix[0,1])\n",
        "  return 1-specificity\n",
        "\n",
        "# This function prints performance metrics and ROC curve given the model name, true labels and predicted labels\n",
        "def print_performance( model_name, true_labels, pred_labels):\n",
        "  # rows are actual, columns are predicted\n",
        "  cmatrix = confusion_matrix(true_labels, pred_labels)\n",
        "  fpr = calc_false_positive(cmatrix)\n",
        "\n",
        "  print('Confusion Matrix: \\n',cmatrix)\n",
        "  print('\\nTesting Accuracy: %.2f'% metrics.accuracy_score(true_labels, pred_labels))\n",
        "  print('Precision:%.2f'%  metrics.precision_score(true_labels, pred_labels))\n",
        "  print('Recall: %.2f'% metrics.recall_score(true_labels, pred_labels))\n",
        "  print('False Positive Rate: %.2f'% fpr)\n",
        "  print('\\nClassification report:', classification_report(true_labels, pred_labels), sep='\\n')\n",
        "  print('AUC: %.2f'% roc_auc_score(true_labels, pred_labels))\n",
        "\n",
        "  false_positive_rate, recall, thresholds = roc_curve(true_labels, pred_labels)\n",
        "  roc_auc = auc(false_positive_rate, recall)\n",
        "  plt.figure()\n",
        "  if CLEAN: clean_status='Clean '\n",
        "  else: clean_status ='Overlapped and Duplicated '\n",
        "  plt.title( model_name+' ROC Curve on '+ clean_status + DATA + ' with Seq Len of '+ str(SEQ_WINDOW))\n",
        "  plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.2f' %roc_auc)\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.plot([0,1], [0,1], 'r--')\n",
        "  plt.xlim([0.0,1.0])\n",
        "  plt.ylim([0.0,1.1])\n",
        "  plt.ylabel('Recall')\n",
        "  plt.xlabel('False Positive Rate (1-Specificity)')\n",
        "  #plt.savefig(model_name+'-ROC.jpg')\n",
        "  plt.show()\n",
        "\n",
        "# Plot a heatmap of confusion matrix given the model name, a classifier model, testing data and the predicted label\n",
        "def color_confusion_matrix( model_name, model, x_test, y_test, y_predicted):\n",
        "  class_names = ['Normal', 'Intrusion']\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(6, 6))\n",
        "  plot_confusion_matrix(model, x_test, y_test, display_labels=class_names, \n",
        "                        values_format='d', ax = ax, cmap=plt.cm.Blues)\n",
        "  plt.title('Confusion Matrix of ' + str(model_name))\n",
        "  #plt.savefig(model_name+'-CM.jpg')\n",
        "  plt.show()\n",
        "\n",
        "  cmatrix = confusion_matrix(y_test, y_predicted)\n",
        "  print(cmatrix)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1SbGMBTCCcw"
      },
      "source": [
        "# Graphing overlaid ROC curves, where each one represents a model AUC score\n",
        "def graph_multi_ROC ():\n",
        "  # Set color for each model\n",
        "  colors = {'KM': 'lightcoral','LR': 'darkorange', 'SVM':'lime', 'NB': 'steelblue',\n",
        "            'NN': 'purple','DT': 'magenta','RF': 'deeppink','KNN': 'darkturquoise',\n",
        "            'BERT': 'darkred', 'GPT': 'blue'}\n",
        "  # Set marker for each model          \n",
        "  markers = {'KM':'1--','LR': 'v--', 'SVM': '^--', 'NN': '*--', 'DT': 'o--', 'RF': '+--', 'KNN': '.--', 'NB': 'x--', 'BERT':'<--', 'GPT': '>--'}\n",
        "  \n",
        "  plt.figure(figsize=(9,6))\n",
        "  try:\n",
        "    plt.plot(KM_test.get('fpr'), KM_test.get('tpr'), markers.get('KM'), color=colors.get('KM'),  label=\"KM - AUC=\" + str(KM_test.get('auc').round(3)))\n",
        "    plt.plot(LR_test.get('fpr'), LR_test.get('tpr'), markers.get('LR'), color=colors.get('LR'),  label=\"LR - AUC=\" + str(LR_test.get('auc').round(3)))\n",
        "    plt.plot(SVM_test.get('fpr'),SVM_test.get('tpr'),markers.get('SVM'),color=colors.get('SVM'), label=\"SVM - AUC=\"+ str(SVM_test.get('auc').round(3)))\n",
        "    plt.plot(NN_test.get('fpr'), NN_test.get('tpr'), markers.get('NN'), color=colors.get('NN'),  label=\"NN - AUC=\" + str(NN_test.get('auc').round(3)))\n",
        "    plt.plot(DT_test.get('fpr'), DT_test.get('tpr'), markers.get('DT'), color=colors.get('DT'),  label=\"DT - AUC=\" + str(DT_test.get('auc').round(3)))\n",
        "    plt.plot(RF_test.get('fpr'), RF_test.get('tpr'), markers.get('RF'), color=colors.get('RF'),  label=\"RF - AUC=\" + str(RF_test.get('auc').round(3)))\n",
        "    plt.plot(KNN_test.get('fpr'),KNN_test.get('tpr'),markers.get('KNN'),color=colors.get('KNN'), label=\"KNN - AUC=\"+ str(KNN_test.get('auc').round(3)))\n",
        "    plt.plot(NB_test.get('fpr'), NB_test.get('tpr'), markers.get('NB'), color=colors.get('NB'),  label=\"NB - AUC=\" + str(NB_test.get('auc').round(3)))\n",
        "  except:\n",
        "    print('only performances of BERT and GPT are available')\n",
        "\n",
        "  plt.plot(BERT_test.get('fpr'),BERT_test.get('tpr'), markers.get('BERT'), color=colors.get('BERT'),  label=\"BERT - AUC=\"+ str(BERT_test.get('auc').round(3)))\n",
        "  plt.plot(GPT_test.get('fpr'),GPT_test.get('tpr'), markers.get('GPT'), color=colors.get('GPT'),  label=\"GPT-2 - AUC=\"+ str(GPT_test.get('auc').round(3)))\n",
        "\n",
        "  plt.plot([0,1], [0,1], 'k--', label='Random Chances')\n",
        "  plt.xlim([0.0,1.0])\n",
        "  plt.ylim([0.0,1.02])\n",
        "  plt.ylabel('Recall')\n",
        "  plt.xlabel('False Positive Rate (1-Specificity)')\n",
        "  plt.legend(loc='lower right') \n",
        "  plt.title( 'Testing ROCs on ' + DATA)\n",
        "  #plt.savefig(DATA_I+'-'+train_or_test+'.jpg', dpi = 80)\n",
        "  plt.show()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ-JMcBqmnN9"
      },
      "source": [
        "# **BERT**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k6L-u3Lmmpb",
        "outputId": "d448d587-890e-4dd7-c196-11367c64416f"
      },
      "source": [
        "!pip install pytorch_pretrained_bert pytorch-nlp"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.10.0.2)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.5.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.3->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.3->boto3->pytorch_pretrained_bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.3->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsHMmMB76B9W"
      },
      "source": [
        "from pytorch_pretrained_bert import BertModel\n",
        "from torch import nn\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import Adam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_NgiJJQm6Xx"
      },
      "source": [
        "**Prepare for Train and test data for BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDMTse2Jm0Bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4151c303-f882-416e-9109-41119e42f4b8"
      },
      "source": [
        "train_texts = []\n",
        "for i in range(x_train.shape[0]):\n",
        "     train_texts.append(\" \".join(np.array(x_train.iloc[i,:]).astype(str)))\n",
        "train_texts = tuple(train_texts) \n",
        "\n",
        "clean_test_texts = []\n",
        "for i in range(test_clean.shape[0]):\n",
        "    clean_test_texts.append(\" \".join(np.array(test_clean.iloc[i,:]).astype(str)))\n",
        "clean_test_texts = tuple(clean_test_texts) \n",
        "\n",
        "unclean_test_texts = []\n",
        "for i in range(test_unclean.shape[0]):\n",
        "     unclean_test_texts.append(\" \".join(np.array(test_unclean.iloc[i,:]).astype(str)))\n",
        "unclean_test_texts = tuple(unclean_test_texts) \n",
        "\n",
        "\n",
        "train_labels        = tuple(y_train.tolist())\n",
        "clean_test_labels   = tuple(y_test_clean.tolist())\n",
        "unclean_test_labels = tuple(y_test_unclean.tolist())\n",
        "\n",
        "len(train_texts), len(train_labels), len(clean_test_texts), len(clean_test_labels), len(unclean_test_texts), len(unclean_test_labels)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(245933, 245933, 92, 92, 105, 105)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf2Lbwylm_ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b71b78b3-cb48-40f4-ff5a-1fc6444486d7"
      },
      "source": [
        "# Tokenizer \n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Example\n",
        "tokenizer.tokenize(train_texts[8])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['83',\n",
              " '59',\n",
              " '4',\n",
              " '2',\n",
              " '2',\n",
              " '2',\n",
              " '5',\n",
              " '50',\n",
              " '27',\n",
              " '4',\n",
              " '27',\n",
              " '88',\n",
              " '167',\n",
              " '167',\n",
              " '167',\n",
              " '17',\n",
              " '5',\n",
              " '4',\n",
              " '50',\n",
              " '27',\n",
              " '2',\n",
              " '5',\n",
              " '4',\n",
              " '18',\n",
              " '2']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B9WKzfendjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd0b37c-4c83-4f04-e7c2-42ceab0a36d1"
      },
      "source": [
        "# Prepare labels\n",
        "# True if intrusion or False if normal\n",
        "# Prepare labels\n",
        "# True if intrusion or False if normal\n",
        "train_y = np.array(train_labels) == 1\n",
        "test_clean_y = np.array(clean_test_labels) == 1\n",
        "test_unclean_y = np.array(unclean_test_labels) == 1\n",
        "\n",
        "train_y.shape, test_clean_y.shape, test_unclean_y.shape, np.mean(train_y), np.mean(test_clean_y)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((245933,), (92,), (105,), 0.4675216420732476, 0.1956521739130435)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dp_XAarnZqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c0e8f7-e1ba-4c84-9d89-299da3dc05a1"
      },
      "source": [
        "# Convert to tokens using tokenizer\n",
        "train_tokens        = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:SEQ_WINDOW] + ['[SEP]'], train_texts))\n",
        "clean_test_tokens   = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:SEQ_WINDOW] + ['[SEP]'], clean_test_texts))\n",
        "unclean_test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:SEQ_WINDOW] + ['[SEP]'], unclean_test_texts))\n",
        "\n",
        "print('Number of Training Sequences:',len(train_tokens), '\\nNumber of Clean Testing Sequences:', len(clean_test_tokens), '\\nNumber of Unclean Testing Sequences:', len(unclean_test_tokens) )       "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training Sequences: 245933 \n",
            "Number of Clean Testing Sequences: 92 \n",
            "Number of Unclean Testing Sequences: 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MH_bWrznbYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e27e42d8-04c7-4af8-c25d-fb24ebe84158"
      },
      "source": [
        "# Following is to convert List of words to list of numbers. (Words are replaced by their index in dictionar)\n",
        "train_tokens_ids         = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen= SEQ_WINDOW, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "clean_test_tokens_ids    = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, clean_test_tokens)),  maxlen= SEQ_WINDOW, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "unclean_test_tokens_ids  = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, unclean_test_tokens)),  maxlen= SEQ_WINDOW, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "\n",
        "train_tokens_ids.shape, clean_test_tokens_ids.shape, unclean_test_tokens_ids.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((245933, 25), (92, 25), (105, 25))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1q-b-LKnfbH"
      },
      "source": [
        "# To mask the paddings\n",
        "train_masks        = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "clean_test_masks   = [[float(i > 0) for i in ii] for ii in clean_test_tokens_ids]\n",
        "unclean_test_masks = [[float(i > 0) for i in ii] for ii in unclean_test_tokens_ids]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZ3gKOtng_v"
      },
      "source": [
        "# Define BERT model\n",
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens, masks=None):\n",
        "        # First Layer\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        \n",
        "        # output layer\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        \n",
        "        return proba\n",
        "      \n",
        "    def train_m(self,x,y,train_mask,epochs,batchsize):\n",
        "      train_tokens_tensor = torch.tensor(x)\n",
        "      train_y_tensor = torch.tensor(y.reshape(-1, 1)).float()\n",
        "      train_masks_tensor = torch.tensor(train_mask)\n",
        "\n",
        "      train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "      train_sampler = RandomSampler(train_dataset)\n",
        "      train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batchsize) \n",
        "\n",
        "\n",
        "      param_optimizer = list(self.sigmoid.named_parameters()) \n",
        "      optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "      optimizer = Adam(self.bert.parameters(), lr=2e-5)\n",
        "      for epoch_num in range(epochs):\n",
        "          self.train() # Training Flag\n",
        "          train_loss = 0\n",
        "          for step_num, batch_data in enumerate(train_dataloader):\n",
        "              \n",
        "              # Load batch on device memory\n",
        "              token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "              # Get the output of the model for provided input\n",
        "              logits = self(token_ids, masks)\n",
        "              \n",
        "              # Loss function\n",
        "              loss_func = nn.BCELoss()\n",
        "\n",
        "              # Calculate Loss\n",
        "              batch_loss = loss_func(logits, labels)\n",
        "              train_loss += batch_loss.item()\n",
        "              \n",
        "              # backpropagate the error\n",
        "              self.zero_grad()\n",
        "              batch_loss.backward()\n",
        "              \n",
        "              # Update the Weights of the Model\n",
        "              clip_grad_norm_(parameters=self.parameters(), max_norm=1.0)\n",
        "              optimizer.step()\n",
        "              \n",
        "              clear_output(wait=True)\n",
        "              print('Epoch: ', epoch_num + 1)\n",
        "              print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_labels) / batchsize, train_loss / (step_num + 1)))        "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA0ADfkpnjgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19691acc-7e40-4f75-af4e-7c31fee86b05"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CZERb2Onk_v"
      },
      "source": [
        "bert_clf = BertBinaryClassifier()\n",
        "bert_clf = bert_clf.cuda()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjM08A0OoGro"
      },
      "source": [
        "**Fine Tune BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUS_cifIn1_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8df830f-e299-42ed-ec0e-9bcde3b1c5c4"
      },
      "source": [
        "# Train BERT NLP\n",
        "bert_clf.train_m(train_tokens_ids,train_y,train_masks, EPOCHS, BATCH_SZ)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n",
            "\r627/15370.8125 loss: 0.4049610388198286 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUTlJLsooNrq"
      },
      "source": [
        "**Evaluate on Testing Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly5Mhn9SoKxw"
      },
      "source": [
        "# Convert token ids to tensor \n",
        "clean_test_tokens_tensor = torch.tensor(clean_test_tokens_ids)\n",
        "unclean_test_tokens_tensor = torch.tensor(unclean_test_tokens_ids)\n",
        "\n",
        "# Convert labels to tensors\n",
        "clean_test_y_tensor = torch.tensor(test_clean_y.reshape(-1, 1)).float()\n",
        "unclean_test_y_tensor = torch.tensor(test_unclean_y.reshape(-1, 1)).float()\n",
        "\n",
        "# Convert to tensro for maks\n",
        "clean_test_masks_tensor   = torch.tensor(clean_test_masks)\n",
        "unclean_test_masks_tensor = torch.tensor(unclean_test_masks)\n",
        "\n",
        "# Load Token, token mask and label into Dataloader\n",
        "clean_test_dataset   = TensorDataset(clean_test_tokens_tensor, clean_test_masks_tensor, clean_test_y_tensor)\n",
        "unclean_test_dataset = TensorDataset(unclean_test_tokens_tensor, unclean_test_masks_tensor, unclean_test_y_tensor)\n",
        "\n",
        "# Define sampler\n",
        "clean_test_sampler = SequentialSampler(clean_test_dataset)\n",
        "unclean_test_sampler = SequentialSampler(unclean_test_dataset)\n",
        "\n",
        "# Defile test data loader\n",
        "clean_test_dataloader   = DataLoader(clean_test_dataset,   sampler = clean_test_sampler,   batch_size=128)\n",
        "unclean_test_dataloader = DataLoader(unclean_test_dataset, sampler = unclean_test_sampler, batch_size=128)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_Bert(dataloader):\n",
        "  bert_clf.eval() # Define eval\n",
        "  bert_predicted = [] # To Store predicted result\n",
        "  all_logits = [] # Actual output that is between 0 to 1 is stored here\n",
        "  with torch.no_grad():\n",
        "      for step_num, batch_data in enumerate(dataloader):\n",
        "\n",
        "          # Load the batch on gpu memory\n",
        "          token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "          # Calculate ouput of bert\n",
        "          logits = bert_clf(token_ids, masks)\n",
        "\n",
        "          # Get the numpy logits\n",
        "          numpy_logits = logits.cpu().detach().numpy()  # Detach from the GPU memory\n",
        "          \n",
        "          # Using the threshold find binary \n",
        "          bert_predicted += list(numpy_logits[:, 0] > 0.5)  # Threshold conversion\n",
        "          all_logits += list(numpy_logits[:, 0])\n",
        "  return bert_predicted\n",
        "\n",
        "def get_Bert_performance(dataloader, label):\n",
        "  bert_predicted = evaluate_Bert(dataloader)\n",
        "  print_performance('BERT', label, bert_predicted)\n",
        "\n",
        "  # Recording TPR and FPR for the TESTING-ROC curves\n",
        "  performance = {}\n",
        "  performance['fpr'], performance['tpr'], thresh = roc_curve(label, bert_predicted)\n",
        "  performance['auc'] = roc_auc_score(label, bert_predicted)\n",
        "  return performance\n",
        "\n"
      ],
      "metadata": {
        "id": "_Lu3SkuxWTv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('----------------------------Evaluating BERT with Clean Data----------------------------')\n",
        "BERT_clean_perf = get_Bert_performance(clean_test_dataloader, test_clean_y)"
      ],
      "metadata": {
        "id": "5-kZjoPnWXAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('----------------------------Evaluating BERT with Unclean Data----------------------------')\n",
        "BERT_unclean_perf = get_Bert_performance(unclean_test_dataloader, test_unclean_y)"
      ],
      "metadata": {
        "id": "XK7rIyecWZPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSuD_5c43X10"
      },
      "source": [
        "# **GPT-2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HueSQ1KsukV"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-gD9nyo4S1D"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('microsoft/DialoGPT-small')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkYOrTFA4YUN"
      },
      "source": [
        "# Padding sequences from the right to a max length of 20\n",
        "tokenizer.padding_side = \"right\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "train_tokens        = tokenizer(train_texts,      return_tensors='pt',  truncation=True,  padding=True,  max_length = SEQ_WINDOW)\n",
        "clean_test_tokens   = tokenizer(clean_test_texts, return_tensors='pt',  truncation=True,  padding=True,  max_length = SEQ_WINDOW)\n",
        "unclean_test_tokens = tokenizer(unclean_test_texts,return_tensors='pt', truncation=True,  padding=True,  max_length = SEQ_WINDOW)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHRofoti4g24"
      },
      "source": [
        "# Following is to convert List of words to list of numbers. (Words are replaced by their index in dictionar)\n",
        "\n",
        "train_tokens_ids        = train_tokens.input_ids\n",
        "clean_test_tokens_ids   = clean_test_tokens.input_ids\n",
        "unclean_test_tokens_ids = unclean_test_tokens.input_ids\n",
        "\n",
        "train_tokens_ids.shape, clean_test_tokens_ids.shape, unclean_test_tokens_ids.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udvDwEdz4haO"
      },
      "source": [
        "train_masks        = train_tokens.attention_mask\n",
        "clean_test_masks   = clean_test_tokens.attention_mask\n",
        "unclean_test_masks = unclean_test_tokens.attention_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23qklJA_6Q2L"
      },
      "source": [
        "**Create GPT-2 Classifer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LiNms1g6PqS"
      },
      "source": [
        "class GTP2BinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(GTP2BinaryClassifier, self).__init__()\n",
        "        self.gtp2 = GPT2ForSequenceClassification.from_pretrained('microsoft/DialoGPT-small')\n",
        "      \n",
        "    def train_m(self,x,y,train_mask,epochs,batchsize):\n",
        "      train_tokens_tensor = torch.tensor(x)\n",
        "      train_y_tensor = torch.tensor(y.reshape(-1, 1)).long()\n",
        "      train_masks_tensor = torch.tensor(train_mask)\n",
        "\n",
        "      train_dataset = TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "      train_sampler = RandomSampler(train_dataset)\n",
        "      train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batchsize) \n",
        "\n",
        "\n",
        "      # param_optimizer = list(self.gtp2.parameters()) \n",
        "      # optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "      optimizer = Adam(self.gtp2.parameters(), lr=5e-5)\n",
        "      for epoch_num in range(epochs):\n",
        "          self.gtp2.train() # Training Flag\n",
        "          train_loss = 0\n",
        "          for step_num, batch_data in enumerate(train_dataloader):\n",
        "              \n",
        "              # Load batch on device memory\n",
        "              token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "              self.zero_grad()\n",
        "\n",
        "              # Get the output of the model for provided input\n",
        "              outputs = self.gtp2(token_ids,attention_mask=masks,labels=labels)\n",
        "              loss, logits = outputs[:2]\n",
        "              # logits = self(token_ids, masks)\n",
        "              \n",
        "              # Total Loss\n",
        "              train_loss += loss.item()\n",
        "              \n",
        "              # Backward pass the loss\n",
        "              loss.backward()\n",
        "              torch.nn.utils.clip_grad_norm_(self.gtp2.parameters(), 1.0)\n",
        "              \n",
        "              optimizer.step()\n",
        "              logits = logits.detach().cpu().numpy()\n",
        "\n",
        "              clear_output(wait=True)\n",
        "        \n",
        "              print('Epoch: ', epoch_num + 1)\n",
        "              print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_labels) / batchsize, train_loss / (step_num + 1)))\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPZ0MZU06Xxu"
      },
      "source": [
        "gtp_clf = GTP2BinaryClassifier()\n",
        "gtp_clf = gtp_clf.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc6BBhJ_6gQL"
      },
      "source": [
        "# Configure the Padding token id\n",
        "gtp_clf.gtp2.config.pad_token_id = tokenizer.eos_token_id\n",
        "gtp_clf.train_m(train_tokens_ids,train_y,train_masks, EPOCHS, BATCH_SZ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIQXu7cL6n1g"
      },
      "source": [
        "**Evaluate on Testing Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpBPha-z6gyA"
      },
      "source": [
        "clean_test_tokens_tensor = torch.tensor(clean_test_tokens_ids)\n",
        "unclean_test_tokens_tensor = torch.tensor(unclean_test_tokens_ids)\n",
        "clean_test_y_tensor   = torch.tensor(test_clean_y.reshape(-1, 1)).long()\n",
        "unclean_test_y_tensor = torch.tensor(test_unclean_y.reshape(-1, 1)).long()\n",
        "\n",
        "clean_test_masks_tensor   = torch.tensor(clean_test_masks)\n",
        "unclean_test_masks_tensor = torch.tensor(unclean_test_masks)\n",
        "\n",
        "\n",
        "clean_test_dataset   = TensorDataset(clean_test_tokens_tensor, clean_test_masks_tensor, clean_test_y_tensor)\n",
        "unclean_test_dataset = TensorDataset(unclean_test_tokens_tensor, unclean_test_masks_tensor, unclean_test_y_tensor)\n",
        "\n",
        "clean_test_sampler = SequentialSampler(clean_test_dataset)\n",
        "unclean_test_sampler = SequentialSampler(unclean_test_dataset)\n",
        "\n",
        "clean_test_dataloader = DataLoader(clean_test_dataset,     sampler= clean_test_sampler,   batch_size=128)\n",
        "unclean_test_dataloader = DataLoader(unclean_test_dataset, sampler= unclean_test_sampler, batch_size=128)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "def evaluate_GPT(dataloader):\n",
        "  gtp_clf.eval() # Define eval\n",
        "  gpt_predicted = [] # Store Result\n",
        "  with torch.no_grad():\n",
        "      for step_num, batch_data in enumerate(dataloader):\n",
        "\n",
        "          token_ids, masks, labels = tuple(t.to(device) for t in batch_data)\n",
        "\n",
        "          # ----------------------------------------------------------------\n",
        "          outputs = gtp_clf.gtp2(token_ids,attention_mask=masks,labels=labels)\n",
        "          loss, logits = outputs[:2]\n",
        "          numpy_logits = logits.detach().cpu().numpy()\n",
        "          # ----------------------------------------------------------------\n",
        "          gpt_predicted +=list(numpy_logits.argmax(axis=-1).flatten().tolist())\n",
        "  return gpt_predicted\n",
        "\n",
        "\n",
        "def get_GPT_performance(dataloader, label):\n",
        "  gpt_predicted = evaluate_GPT(dataloader)\n",
        "  print_performance('GPT', label, gpt_predicted)\n",
        "\n",
        "  # Recording TPR and FPR for the TESTING-ROC curves\n",
        "  performance = {}\n",
        "  performance['fpr'], performance['tpr'], thresh = roc_curve(label, gpt_predicted)\n",
        "  performance['auc'] = roc_auc_score(label, gpt_predicted)\n",
        "  return performance"
      ],
      "metadata": {
        "id": "P9Az4S2KXKzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('----------------------------Evaluating GPT with Clean Data----------------------------')\n",
        "GPT_clean_perf = get_GPT_performance(clean_test_dataloader, test_clean_y)"
      ],
      "metadata": {
        "id": "K1oq6bS3XMcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('----------------------------Evaluating GPT with Unclean Data----------------------------')\n",
        "GPT_unclean_perf = get_GPT_performance(unclean_test_dataloader, test_unclean_y)"
      ],
      "metadata": {
        "id": "0iNlJ50cXOjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJgQwUXi62OA"
      },
      "source": [
        "# Ploting the overlaid ROC curves on testing results:\n",
        "#graph_multi_ROC()\n",
        "\n",
        "\n",
        "def plot_ROC_Clean_Unclean(clean, unclean, model_name):\n",
        "  colors = {'unclean': 'lightcoral','clean': 'blue'}\n",
        "\n",
        "  plt.plot(clean.get('fpr'), clean.get('tpr'), color=colors.get('clean'),  label= \"AUC on Clean Data =\" + str( round(clean.get('auc'), 3) ) )   \n",
        "  plt.plot(unclean.get('fpr'), unclean.get('tpr'), color=colors.get('unclean'),  label= \"AUC on Unclean Data =\" + str( round(unclean.get('auc'), 3) ) )   \n",
        "  plt.title(model_name +' Performance on Clean and Unclean Data')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "plot_ROC_Clean_Unclean(BERT_clean_perf, BERT_unclean_perf, 'BERT')\n",
        "plot_ROC_Clean_Unclean(GPT_clean_perf, GPT_unclean_perf, 'GPT')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-KVm3qLDNsk"
      },
      "source": [
        "# **Write performance measures to file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CIEcZ4ke9k1"
      },
      "source": [
        "# Save performance measure dict of each model to a file\n",
        "def write_to_file (varname, model_name, clean):\n",
        "  clean_status = 'clean' if CLEAN else 'unclean'\n",
        "  filename = DATA +'-'+ str(SEQ_WINDOW) +'-'+ clean_status + \"-model.txt\"\n",
        "  file = open(filename, \"a\")\n",
        "  str_dictionary = repr(varname)\n",
        "  file.write(\"{}_test_{} = \".format(model_name, clean) + str_dictionary + \"\\n\")\n",
        "  file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uusevnMCe9kO"
      },
      "source": [
        "write_to_file(BERT_clean_perf,   'BERT', 'clean')\n",
        "write_to_file(BERT_unclean_perf, 'BERT', 'unclean')\n",
        "\n",
        "write_to_file(GPT_clean_perf,   'GPT', 'clean')\n",
        "write_to_file(GPT_unclean_perf, 'GPT', 'unclean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "print(BERT_test)\n",
        "\n",
        "print('\\n',GPT_test)"
      ],
      "metadata": {
        "id": "yE_RchiQ68eJ"
      }
    }
  ]
}